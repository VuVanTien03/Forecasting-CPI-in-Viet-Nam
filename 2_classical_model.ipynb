{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a749466b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 5 out of 5 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target                  Model      RMSE       MAE      MAPE     sMAPE  \\\n",
      "0  cpi_mom                  ARIMA  0.342721  0.274343  0.273675  0.273471   \n",
      "1  cpi_mom  Exponential Smoothing  0.228608  0.191115  0.190825  0.190594   \n",
      "2  cpi_mom                Prophet  0.241135  0.173548  0.173083  0.172993   \n",
      "3  cpi_mom                 SARIMA  0.327964  0.253911  0.253186  0.253048   \n",
      "4  cpi_mom                SARIMAX  0.314712  0.239798  0.239112  0.238990   \n",
      "\n",
      "   NormMAPE     DirAcc  \n",
      "0  0.002730  63.636364  \n",
      "1  0.001904  36.363636  \n",
      "2  0.001727  72.727273  \n",
      "3  0.002526  36.363636  \n",
      "4  0.002385  54.545455  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.api import VAR\n",
    "import pmdarima as pm\n",
    "from prophet import Prophet\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "img_dir = 'classical_model_results'\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=f'{img_dir}/classical_models_log.txt',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "CONFIG = {\n",
    "    'forecast_horizon': 12,\n",
    "    'seasonal_periods': 12,\n",
    "    'min_data_length': 24,\n",
    "    'img_dir': img_dir,\n",
    "    'results_file': f'{img_dir}/classical_model_results.csv',\n",
    "    'n_jobs': -1,\n",
    "    'outlier_threshold': 3,\n",
    "    'max_diff': 3,\n",
    "    'lag_features': list(range(1, 13)),\n",
    "    'rolling_windows': [3, 6, 12],\n",
    "    'correlation_threshold': 0.15,\n",
    "}\n",
    "\n",
    "def detect_outliers(series, threshold=CONFIG['outlier_threshold']):\n",
    "    z_scores = np.abs((series - series.mean()) / series.std())\n",
    "    outliers = z_scores > threshold\n",
    "    series_clean = series.copy()\n",
    "    series_clean[outliers] = series.mean()\n",
    "    logger.info(f\"Detected {outliers.sum()} outliers in series\")\n",
    "    return series_clean\n",
    "\n",
    "def validate_input_data(df, required_columns):\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns: {required_columns}\")\n",
    "    if df.index.duplicated().any():\n",
    "        raise ValueError(\"Index contains duplicates!\")\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        raise ValueError(\"Index is not monotonically increasing!\")\n",
    "    if df[required_columns].isnull().sum().any():\n",
    "        logger.warning(f\"Missing values in data: {df[required_columns].isnull().sum().to_dict()}\")\n",
    "        df[required_columns] = df[required_columns].fillna(method='ffill').fillna(df[required_columns].mean())\n",
    "    if df[required_columns].replace([np.inf, -np.inf], np.nan).isnull().sum().any():\n",
    "        raise ValueError(\"Data contains infinite values!\")\n",
    "    if not all(df[required_columns].dtypes.apply(lambda x: np.issubdtype(x, np.number))):\n",
    "        raise ValueError(\"Some columns are not numeric!\")\n",
    "\n",
    "def check_stationarity(series, name):\n",
    "    max_diff = CONFIG['max_diff']\n",
    "    series_clean = series.dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(series_clean) < 2:\n",
    "        logger.error(f\"{name}: Data too short after cleaning!\")\n",
    "        return 0\n",
    "    d = 0\n",
    "    while d <= max_diff:\n",
    "        result = adfuller(series_clean)\n",
    "        logger.info(f\"ADF Test for {name} (d={d}): Statistic={result[0]:.4f}, p-value={result[1]:.4f}\")\n",
    "        if result[1] < 0.05:\n",
    "            logger.info(f\"{name} stationary at differencing order d={d}\")\n",
    "            return d\n",
    "        if d == max_diff:\n",
    "            logger.warning(f\"{name} not stationary after {max_diff} differencing. Using d={d}.\")\n",
    "            return d\n",
    "        series_clean = series_clean.diff().dropna()\n",
    "        if len(series_clean) < 2:\n",
    "            logger.warning(f\"{name}: Data too short after differencing {d+1}!\")\n",
    "            return d\n",
    "        d += 1\n",
    "    return d\n",
    "\n",
    "def create_features(\n",
    "    data: pd.DataFrame,\n",
    "    target: str,\n",
    "    lags: list = CONFIG['lag_features'],\n",
    "    rolling_windows: list = CONFIG['rolling_windows'],\n",
    "    seasonal_features: bool = True,\n",
    "    fill_method: str = 'ffill'\n",
    ") -> pd.DataFrame:\n",
    "    logger.info(f\"Creating features for {target}, data shape: {data.shape}\")\n",
    "    if len(data) < CONFIG['min_data_length']:\n",
    "        raise ValueError(f\"Data too short: {len(data)} rows\")\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"DataFrame index must be DatetimeIndex\")\n",
    "    if data.index.duplicated().any():\n",
    "        raise ValueError(\"Index contains duplicates\")\n",
    "    if not data.index.is_monotonic_increasing:\n",
    "        data = data.sort_index()\n",
    "    exog_var = 'cpi_yoy'\n",
    "    required_cols = [target, exog_var]\n",
    "    if not all(col in data.columns for col in required_cols):\n",
    "        raise ValueError(f\"Missing columns: {required_cols}\")\n",
    "    df = data.copy()\n",
    "    if df[required_cols].isna().any().any() or np.isinf(df[required_cols]).any().any():\n",
    "        logger.warning(f\"Data contains NaN or Inf in {required_cols}, filling...\")\n",
    "        df[required_cols] = df[required_cols].fillna(method='ffill').fillna(df[required_cols].mean())\n",
    "    for col in required_cols:\n",
    "        for lag in lags:\n",
    "            df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "        for window in rolling_windows:\n",
    "            df[f'{col}_roll_mean_{window}'] = df[col].rolling(window=window).mean()\n",
    "            df[f'{col}_roll_std_{window}'] = df[col].rolling(window=window).std()\n",
    "    if seasonal_features:\n",
    "        df['month'] = df.index.month\n",
    "        df = pd.get_dummies(df, columns=['month'], prefix='month')\n",
    "        period = CONFIG['seasonal_periods']\n",
    "        df['month_sin'] = np.sin(2 * np.pi * df.index.month / period)\n",
    "        df['month_cos'] = np.cos(2 * np.pi * df.index.month / period)\n",
    "        logger.info(\"Added seasonal features\")\n",
    "    df['quarter'] = df.index.quarter\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().all():\n",
    "            raise ValueError(f\"Column {col} contains only NaN\")\n",
    "        if df[col].isnull().any():\n",
    "            df[col] = df[col].fillna(method=fill_method).fillna(df[col].mean())\n",
    "            logger.info(f\"Filled NaN in {col} with {fill_method} and mean\")\n",
    "    if df.isnull().any().any():\n",
    "        raise ValueError(f\"Data still contains NaN: {df.isnull().sum().to_dict()}\")\n",
    "    correlations = df.corr()[target].drop(required_cols, errors='ignore')\n",
    "    low_corr_cols = correlations[abs(correlations) < CONFIG['correlation_threshold']].index\n",
    "    if low_corr_cols.any():\n",
    "        logger.info(f\"Dropping low-correlation features: {list(low_corr_cols)}\")\n",
    "        df = df.drop(columns=low_corr_cols)\n",
    "    logger.info(f\"Features after processing: {list(df.columns)}\")\n",
    "    return df\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    actual = np.array(actual, dtype=float)\n",
    "    predicted = np.array(predicted, dtype=float)\n",
    "    valid_mask = ~np.isnan(actual) & ~np.isnan(predicted) & ~np.isinf(actual) & ~np.isinf(predicted)\n",
    "    actual = actual[valid_mask]\n",
    "    predicted = predicted[valid_mask]\n",
    "    if len(actual) == 0:\n",
    "        logger.warning(\"No valid data for metrics calculation!\")\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mape = mean_absolute_percentage_error(actual, predicted) * 100 if np.all(np.abs(actual) > 1e-8) else np.nan\n",
    "    smape = 100 * np.mean(2 * np.abs(predicted - actual) / (np.abs(actual) + np.abs(predicted)))\n",
    "    norm_mape = mape / np.mean(np.abs(actual)) if not np.isnan(mape) else np.nan\n",
    "    directional_acc = np.mean((np.diff(actual) * np.diff(predicted)) > 0) * 100 if len(actual) > 1 else np.nan\n",
    "    return rmse, mae, mape, smape, norm_mape, directional_acc\n",
    "\n",
    "def plot_decomposition(series, period, filename):\n",
    "    decomposition = seasonal_decompose(series, period=period, model='additive')\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(411); plt.plot(series.index, series, label='Original'); plt.legend(loc='upper left')\n",
    "    plt.subplot(412); plt.plot(series.index, decomposition.trend, label='Trend'); plt.legend(loc='upper left')\n",
    "    plt.subplot(413); plt.plot(series.index, decomposition.seasonal, label='Seasonal'); plt.legend(loc='upper left')\n",
    "    plt.subplot(414); plt.plot(series.index, decomposition.resid, label='Residual'); plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=300)\n",
    "        logger.info(f\"Saved decomposition plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving decomposition plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_forecast(historical, test, forecast, forecast_index, title, ylabel, filename, confidence_intervals=None):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(historical.index, historical, label='Historical', color='blue')\n",
    "    plt.plot(test.index, test, label='Actual (Test)', color='green')\n",
    "    plt.plot(forecast_index, forecast, label='Forecast', color='orange', linestyle='--', linewidth=2)\n",
    "    if confidence_intervals:\n",
    "        plt.fill_between(forecast_index, confidence_intervals[0], confidence_intervals[1], color='orange', alpha=0.2, label='95% CI')\n",
    "    plt.title(title); plt.xlabel('Time'); plt.ylabel(ylabel); plt.legend(); plt.grid(True)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    plt.xticks(rotation=45); plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=300)\n",
    "        logger.info(f\"Saved plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_comparison_forecasts(historical, test, forecasts, forecast_index, title, ylabel, filename, metrics=None):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(historical.index, historical, label='Historical', color='blue')\n",
    "    plt.plot(test.index, test, label='Actual (Test)', color='green')\n",
    "    colors = sns.color_palette(\"husl\", len(forecasts))\n",
    "    for (model_name, forecast), color in zip(forecasts.items(), colors):\n",
    "        rmse = metrics.get(model_name, {}).get('RMSE', np.nan) if metrics else np.nan\n",
    "        if forecast is None or pd.isna(rmse):\n",
    "            continue\n",
    "        plt.plot(forecast_index, forecast, label=f'Forecast {model_name} (RMSE: {rmse:.4f})', linestyle='--', color=color)\n",
    "    plt.title(title); plt.xlabel('Time'); plt.ylabel(ylabel); plt.legend(); plt.grid(True)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    plt.xticks(rotation=45); plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=300)\n",
    "        logger.info(f\"Saved comparison plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving comparison plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_bar(metrics_df, filename):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    metrics = ['RMSE', 'MAE', 'MAPE', 'sMAPE', 'NormMAPE', 'DirAcc']\n",
    "    for i, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.barplot(x='Model', y=metric, data=metrics_df)\n",
    "        plt.title(f'{metric} Comparison')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=300)\n",
    "        logger.info(f\"Saved metrics bar plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving metrics bar plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_residual_acf(residuals, title, filename):\n",
    "    if residuals is None or len(residuals) < 2:\n",
    "        logger.warning(f\"Skipping ACF: Insufficient residual data - {title}\")\n",
    "        return\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    max_lags = min(20, len(residuals) - 1)\n",
    "    if max_lags < 1:\n",
    "        return\n",
    "    try:\n",
    "        plot_acf(residuals, lags=max_lags, title=title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=300)\n",
    "        logger.info(f\"Saved ACF plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving ACF plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def run_exponential_smoothing(train, test, forecast_index, seasonal_periods=CONFIG['seasonal_periods']):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=seasonal_periods).fit(optimized=True)\n",
    "        forecast = model.forecast(CONFIG['forecast_horizon'])\n",
    "        residuals = train - model.fittedvalues\n",
    "        forecast = pd.Series(forecast.values, index=forecast_index)\n",
    "        resid_std = np.std(residuals)\n",
    "        ci_lower = forecast - 1.96 * resid_std\n",
    "        ci_upper = forecast + 1.96 * resid_std\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Exponential Smoothing: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, (ci_lower, ci_upper)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Exponential Smoothing: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_arima(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        d = check_stationarity(train, \"ARIMA\")\n",
    "        try:\n",
    "            model = pm.auto_arima(train, start_p=0, start_q=0, max_p=3, max_q=3, d=d, max_d=2,\n",
    "                                  seasonal=False, stepwise=True, trace=False, error_action='ignore',\n",
    "                                  suppress_warnings=True, information_criterion='aic', maxiter=50)\n",
    "        except:\n",
    "            logger.warning(\"auto_arima failed, using ARIMA(1,1,1)\")\n",
    "            model = pm.ARIMA(order=(1,1,1), suppress_warnings=True).fit(train)\n",
    "        forecast = model.predict(n_periods=CONFIG['forecast_horizon'])\n",
    "        residuals = train - model.predict_in_sample()\n",
    "        forecast = pd.Series(forecast, index=forecast_index)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"ARIMA (order={model.order}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error ARIMA: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_sarima(train, test, forecast_index, seasonal_periods=CONFIG['seasonal_periods']):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        d = check_stationarity(train, \"SARIMA\")\n",
    "        try:\n",
    "            model = pm.auto_arima(train, start_p=0, start_q=0, max_p=3, max_q=3, d=d, max_d=2,\n",
    "                                  seasonal=True, m=seasonal_periods, start_P=0, start_Q=0, max_P=2, max_Q=2, max_D=1,\n",
    "                                  stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
    "                                  information_criterion='aic', maxiter=50)\n",
    "        except:\n",
    "            logger.warning(\"auto_arima failed, using SARIMA(1,1,1)(1,1,1,12)\")\n",
    "            model = pm.ARIMA(order=(1,1,1), seasonal_order=(1,1,1,seasonal_periods), suppress_warnings=True).fit(train)\n",
    "        forecast = model.predict(n_periods=CONFIG['forecast_horizon'])\n",
    "        residuals = train - model.predict_in_sample()\n",
    "        forecast = pd.Series(forecast, index=forecast_index)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"SARIMA (order={model.order}, seasonal_order={model.seasonal_order}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error SARIMA: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_sarimax(train, test, forecast_index, exog_train, exog_test):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        if exog_train.isna().any().any() or exog_test.isna().any().any():\n",
    "            logger.warning(\"Exogenous data contains NaN, filling...\")\n",
    "            exog_train = exog_train.fillna(method='ffill').fillna(exog_train.mean())\n",
    "            exog_test = exog_test.fillna(method='ffill').fillna(exog_test.mean())\n",
    "        if len(exog_train) != len(train) or len(exog_test) != CONFIG['forecast_horizon']:\n",
    "            raise ValueError(f\"Exogenous data size mismatch: exog_train={len(exog_train)}, train={len(train)}, exog_test={len(exog_test)}\")\n",
    "        d = check_stationarity(train, \"SARIMAX\")\n",
    "        try:\n",
    "            model = pm.auto_arima(train, exogenous=exog_train, start_p=0, start_q=0, max_p=3, max_q=3, d=d, max_d=2,\n",
    "                                  seasonal=True, m=CONFIG['seasonal_periods'], start_P=0, start_Q=0, max_P=1, max_Q=1, max_D=1,\n",
    "                                  stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
    "                                  information_criterion='aic', maxiter=50)\n",
    "        except:\n",
    "            logger.warning(\"auto_arima failed, using SARIMAX(1,1,1)(1,0,1,12)\")\n",
    "            model = pm.ARIMA(order=(1,1,1), seasonal_order=(1,0,1,CONFIG['seasonal_periods']), suppress_warnings=True).fit(train, exogenous=exog_train)\n",
    "        forecast = model.predict(n_periods=CONFIG['forecast_horizon'], exogenous=exog_test)\n",
    "        residuals = train - model.predict_in_sample(exogenous=exog_train)\n",
    "        forecast = pd.Series(forecast, index=forecast_index)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"SARIMAX (order={model.order}, seasonal_order={model.seasonal_order}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error SARIMAX: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_prophet(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        df_train = pd.DataFrame({'ds': train.index, 'y': train.values})\n",
    "        model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False,\n",
    "                        changepoint_prior_scale=0.05, seasonality_prior_scale=10.0).fit(df_train)\n",
    "        future = pd.DataFrame({'ds': forecast_index})\n",
    "        forecast = model.predict(future)\n",
    "        forecast_series = pd.Series(forecast['yhat'].values, index=forecast_index)\n",
    "        residuals = train - model.predict(df_train)['yhat']\n",
    "        ci_lower = pd.Series(forecast['yhat_lower'].values, index=forecast_index)\n",
    "        ci_upper = pd.Series(forecast['yhat_upper'].values, index=forecast_index)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast_series)\n",
    "        logger.info(f\"Prophet: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast_series, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, (ci_lower, ci_upper)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Prophet: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "\n",
    "def run_model_for_target(target, train, test, forecast_index, model_name, model_func, params):\n",
    "    logger.info(f\"Running {model_name} for {target}\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        if model_name == 'SARIMAX':\n",
    "            exog_var = 'cpi_yoy'\n",
    "            feature_cols = [exog_var] + [f'{target}_lag_{lag}' for lag in CONFIG['lag_features']] + \\\n",
    "                           [f'{target}_roll_mean_{w}' for w in CONFIG['rolling_windows']] + \\\n",
    "                           [f'{target}_roll_std_{w}' for w in CONFIG['rolling_windows']] + \\\n",
    "                           [f'{exog_var}_lag_{lag}' for lag in CONFIG['lag_features']] + \\\n",
    "                           [f'{exog_var}_roll_mean_{w}' for w in CONFIG['rolling_windows']] + \\\n",
    "                           [f'{exog_var}_roll_std_{w}' for w in CONFIG['rolling_windows']] + \\\n",
    "                           [col for col in train.columns if col.startswith('month_') or col in ['month_sin', 'month_cos', 'quarter']]\n",
    "            feature_cols = [col for col in feature_cols if col in train.columns]\n",
    "            exog_train = train[feature_cols]\n",
    "            exog_test = pd.DataFrame(index=forecast_index)\n",
    "            exog_test[exog_var] = test[exog_var].reindex(forecast_index).fillna(train[exog_var].iloc[-1]).fillna(train[exog_var].mean())\n",
    "            for col in feature_cols:\n",
    "                if col != exog_var:\n",
    "                    exog_test[col] = train[col].iloc[-1] if col in train.columns else train[exog_var].mean()\n",
    "            if exog_train.isna().any().any() or exog_test.isna().any().any():\n",
    "                logger.warning(f\"Exogenous data still contains NaN after filling\")\n",
    "                exog_train = exog_train.fillna(exog_train.mean())\n",
    "                exog_test = exog_test.fillna(exog_test.mean())\n",
    "            forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, ci = model_func(\n",
    "                train[target], test[target], forecast_index, exog_train, exog_test, **params\n",
    "            )\n",
    "        else:\n",
    "            forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, ci = model_func(\n",
    "                train[target], test[target], forecast_index, **params\n",
    "            )\n",
    "        if forecast is None or pd.isna(rmse):\n",
    "            logger.error(f\"{model_name} for {target} failed to produce valid forecast or RMSE\")\n",
    "            return None\n",
    "        plot_forecast(train[target][-36:], test[target], forecast, forecast_index,\n",
    "                      f'{model_name} Forecast for {target}', target, f'{target}_{model_name}_forecast.png', ci)\n",
    "        if residuals is not None:\n",
    "            plot_residual_acf(residuals.dropna(), f'ACF of Residuals - {model_name} ({target})',\n",
    "                              f'{target}_{model_name}_acf.png')\n",
    "        logger.info(f\"Completed {model_name} for {target} in {time.time() - start_time:.2f}s\")\n",
    "        return {\n",
    "            'Target': target,\n",
    "            'Model': model_name,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'sMAPE': smape,\n",
    "            'NormMAPE': norm_mape,\n",
    "            'DirAcc': dir_acc,\n",
    "            'Forecast': forecast,\n",
    "            'Residuals': residuals,\n",
    "            'CI': ci\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running {model_name} for {target}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        data = pd.read_csv('data/analyzed_time_series.csv')\n",
    "        data['time'] = pd.to_datetime(data['time'])\n",
    "        data.set_index('time', inplace=True)\n",
    "        required_columns = ['cpi_mom', 'cpi_yoy']\n",
    "        validate_input_data(data, required_columns)\n",
    "        for col in required_columns:\n",
    "            data[col] = detect_outliers(data[col])\n",
    "        data_features = create_features(data, 'cpi_mom')\n",
    "        train_size = len(data) - CONFIG['forecast_horizon']\n",
    "        train, test = data_features[:train_size], data_features[train_size:]\n",
    "        forecast_index = pd.date_range(start=test.index[0], periods=CONFIG['forecast_horizon'], freq='MS')\n",
    "        plot_decomposition(data['cpi_mom'], period=CONFIG['seasonal_periods'], filename='cpi_mom_decomposition.png')\n",
    "        models = {\n",
    "            'ARIMA': (run_arima, {}),\n",
    "            'Exponential Smoothing': (run_exponential_smoothing, {}),\n",
    "            'Prophet': (run_prophet, {}),\n",
    "            'SARIMA': (run_sarima, {}),\n",
    "            'SARIMAX': (run_sarimax, {})\n",
    "        }\n",
    "        results = []\n",
    "        forecasts_mom = {}\n",
    "        metrics_mom = {}\n",
    "        logger.info(\"Running models for cpi_mom\")\n",
    "        tasks = [delayed(run_model_for_target)('cpi_mom', train, test, forecast_index, model_name, model_func, params)\n",
    "                 for model_name, (model_func, params) in models.items()]\n",
    "        model_results = Parallel(n_jobs=CONFIG['n_jobs'], verbose=1)(tasks)\n",
    "        for result in model_results:\n",
    "            if result is not None:\n",
    "                results.append({\n",
    "                    'Target': result['Target'],\n",
    "                    'Model': result['Model'],\n",
    "                    'RMSE': result['RMSE'],\n",
    "                    'MAE': result['MAE'],\n",
    "                    'MAPE': result['MAPE'],\n",
    "                    'sMAPE': result['sMAPE'],\n",
    "                    'NormMAPE': result['NormMAPE'],\n",
    "                    'DirAcc': result['DirAcc']\n",
    "                })\n",
    "                forecasts_mom[result['Model']] = result['Forecast']\n",
    "                metrics_mom[result['Model']] = {'RMSE': result['RMSE']}\n",
    "            else:\n",
    "                logger.warning(f\"Result for a cpi_mom model is None, skipping!\")\n",
    "        # if forecasts_mom:\n",
    "            # ensemble_result = run_model_for_target('cpi_mom', train, test, forecast_index, 'Ensemble', run_ensemble,\n",
    "            #                                       {'forecasts': forecasts_mom, 'metrics': metrics_mom})\n",
    "            # if ensemble_result is not None:\n",
    "            #     results.append({\n",
    "            #         'Target': ensemble_result['Target'],\n",
    "            #         'Model': ensemble_result['Model'],\n",
    "            #         'RMSE': ensemble_result['RMSE'],\n",
    "            #         'MAE': ensemble_result['MAE'],\n",
    "            #         'MAPE': ensemble_result['MAPE'],\n",
    "            #         'sMAPE': ensemble_result['sMAPE'],\n",
    "            #         'NormMAPE': ensemble_result['NormMAPE'],\n",
    "            #         'DirAcc': ensemble_result['DirAcc']\n",
    "            #     })\n",
    "            #     forecasts_mom[ensemble_result['Model']] = ensemble_result['Forecast']\n",
    "            #     metrics_mom[ensemble_result['Model']] = {'RMSE': ensemble_result['RMSE']}\n",
    "        if forecasts_mom:\n",
    "            plot_comparison_forecasts(train['cpi_mom'][-36:], test['cpi_mom'], forecasts_mom, forecast_index,\n",
    "                                     'Comparison of Forecasts for cpi_mom', 'cpi_mom', 'cpi_mom_model_comparison.png',\n",
    "                                     metrics=metrics_mom)\n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(results_df)\n",
    "        results_df.to_csv(CONFIG['results_file'], index=False)\n",
    "        logger.info(f\"Results saved to {CONFIG['results_file']}\")\n",
    "        if not results_df.empty:\n",
    "            plot_metrics_bar(results_df, 'cpi_mom_metrics_comparison.png')\n",
    "        if forecasts_mom:\n",
    "            combined_forecast = pd.DataFrame({'Date': forecast_index})\n",
    "            for model_name, forecast in forecasts_mom.items():\n",
    "                combined_forecast[f'{model_name}_cpi_mom'] = forecast\n",
    "            combined_forecast.to_csv(f'{img_dir}/combined_forecast_cpi_mom.csv', index=False)\n",
    "            logger.info(f\"Combined forecasts saved to {img_dir}/combined_forecast_cpi_mom.csv\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main program error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
