{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d0ddf323",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 3 out of 3 | elapsed:  3.2min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Target                  Model      RMSE       MAE        MAPE       sMAPE  \\\n",
            "0  cpi_mom  Exponential Smoothing  0.319763  0.285126  256.581561  140.962257   \n",
            "1  cpi_mom                 SARIMA  0.325483  0.286272  252.902878  137.211902   \n",
            "2  cpi_mom                Prophet  0.296743  0.241665  226.573355  116.287847   \n",
            "\n",
            "     NormMAPE     DirAcc  \n",
            "0  752.574411  36.363636  \n",
            "1  741.784539  36.363636  \n",
            "2  664.557923  45.454545  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import pmdarima as pm\n",
        "from prophet import Prophet\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from joblib import Parallel, delayed\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import uuid\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "CONFIG = {\n",
        "    'forecast_horizon': 12,\n",
        "    'seasonal_periods': 12,\n",
        "    'min_data_length': 24,\n",
        "    'img_dir': 'classical_model_results',\n",
        "    'results_file': 'classical_model_results/classical_model_results.csv',\n",
        "    'n_jobs': -1,  # Có thể giới hạn, ví dụ: 4, nếu máy có ít CPU\n",
        "    'outlier_threshold': 3,\n",
        "    'max_diff': 3,\n",
        "    'lag_features': list(range(1, 13)),\n",
        "    'rolling_windows': [3, 6, 12],\n",
        "    'correlation_threshold': 0.2,\n",
        "    'dpi': 150,  # Giảm DPI để tăng tốc lưu biểu đồ\n",
        "}\n",
        "\n",
        "# Setup logging\n",
        "def setup_logging(img_dir):\n",
        "    os.makedirs(img_dir, exist_ok=True)\n",
        "    logging.basicConfig(\n",
        "        filename=f'{img_dir}/classical_models_log.txt',\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "    return logging.getLogger(__name__)\n",
        "\n",
        "def detect_outliers(series, threshold=CONFIG['outlier_threshold']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    z_scores = np.abs((series - series.mean()) / series.std())\n",
        "    outliers = z_scores > threshold\n",
        "    series_clean = series.copy()\n",
        "    series_clean[outliers] = series.mean()\n",
        "    logger.info(f\"Detected {outliers.sum()} outliers\")\n",
        "    return series_clean\n",
        "\n",
        "# Feature Engineering\n",
        "def create_features(data, target, config=CONFIG):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(f\"Creating features for {target}, data shape: {data.shape}\")\n",
        "    \n",
        "    if len(data) < config['min_data_length']:\n",
        "        raise ValueError(f\"Data too short: {len(data)} rows\")\n",
        "    if not isinstance(data.index, pd.DatetimeIndex):\n",
        "        raise ValueError(\"DataFrame index must be DatetimeIndex\")\n",
        "    \n",
        "    if target not in data.columns:\n",
        "        raise ValueError(f\"Target column {target} not found in data\")\n",
        "    \n",
        "    df = data.copy()\n",
        "    required_cols = [target]\n",
        "    \n",
        "    # Handle missing/infinite values once\n",
        "    if df.isna().any().any() or np.isinf(df).any().any():\n",
        "        logger.warning(\"Data contains NaN or Inf, filling...\")\n",
        "        df = df.fillna(method='ffill').fillna(df.mean(numeric_only=True))\n",
        "    \n",
        "    # Vectorized lag and rolling features\n",
        "    lag_features = {f'{target}_lag_{lag}': df[target].shift(lag) for lag in config['lag_features']}\n",
        "    rolling_features = {\n",
        "        f'{target}_roll_{stat}_{window}': getattr(df[target].rolling(window=window), stat)()\n",
        "        for window in config['rolling_windows']\n",
        "        for stat in ['mean', 'std']\n",
        "    }\n",
        "    df = df.assign(**lag_features, **rolling_features)\n",
        "    \n",
        "    # Add seasonal features\n",
        "    df = df.assign(\n",
        "        month=df.index.month,\n",
        "        month_sin=np.sin(2 * np.pi * df.index.month / config['seasonal_periods']),\n",
        "        month_cos=np.cos(2 * np.pi * df.index.month / config['seasonal_periods']),\n",
        "        quarter=df.index.quarter\n",
        "    )\n",
        "    df = pd.get_dummies(df, columns=['month'], prefix='month')\n",
        "    \n",
        "    # Remove low-correlation features\n",
        "    try:\n",
        "        correlations = df.corr(numeric_only=True)[target].drop(required_cols, errors='ignore')\n",
        "        low_corr_cols = correlations[abs(correlations) < config['correlation_threshold']].index\n",
        "        if low_corr_cols.any():\n",
        "            logger.info(f\"Dropping {len(low_corr_cols)} low-correlation features: {list(low_corr_cols)}\")\n",
        "            df = df.drop(columns=low_corr_cols)\n",
        "        else:\n",
        "            logger.info(\"No features dropped due to low correlation\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error calculating correlations: {str(e)}\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Stationarity Check\n",
        "def check_stationarity(series, name, max_diff=CONFIG['max_diff']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    series_clean = series.dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
        "    if len(series_clean) < 2:\n",
        "        logger.error(f\"{name}: Data too short after cleaning!\")\n",
        "        return 0\n",
        "    \n",
        "    d = 0\n",
        "    while d <= max_diff:\n",
        "        result = adfuller(series_clean)\n",
        "        if result[1] < 0.05:\n",
        "            logger.info(f\"{name} stationary at d={d}\")\n",
        "            return d\n",
        "        if d == max_diff:\n",
        "            logger.warning(f\"{name} not stationary after {max_diff} differencing\")\n",
        "            return d\n",
        "        series_clean = series_clean.diff().dropna()\n",
        "        if len(series_clean) < 2:\n",
        "            logger.warning(f\"{name}: Data too short after differencing {d+1}\")\n",
        "            return d\n",
        "        d += 1\n",
        "    return d\n",
        "\n",
        "# Model Evaluation Metrics\n",
        "def calculate_metrics(actual, predicted):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    actual = np.array(actual, dtype=float)\n",
        "    predicted = np.array(predicted, dtype=float)\n",
        "    valid_mask = ~np.isnan(actual) & ~np.isnan(predicted) & ~np.isinf(actual) & ~np.isinf(predicted)\n",
        "    actual = actual[valid_mask]\n",
        "    predicted = predicted[valid_mask]\n",
        "    \n",
        "    if len(actual) == 0:\n",
        "        logger.warning(\"No valid data for metrics calculation!\")\n",
        "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    mape = mean_absolute_percentage_error(actual, predicted) * 100 if np.all(np.abs(actual) > 1e-8) else np.nan\n",
        "    smape = 100 * np.mean(2 * np.abs(predicted - actual) / (np.abs(actual) + np.abs(predicted)))\n",
        "    norm_mape = mape / np.mean(np.abs(actual)) if not np.isnan(mape) else np.nan\n",
        "    directional_acc = np.mean((np.diff(actual) * np.diff(predicted)) > 0) * 100 if len(actual) > 1 else np.nan\n",
        "    return rmse, mae, mape, smape, norm_mape, directional_acc\n",
        "\n",
        "# Visualization Functions\n",
        "def plot_decomposition(series, period, filename, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    if series.isna().any():\n",
        "        logger.warning(f\"Series has {series.isna().sum()} NaN values, filling...\")\n",
        "        series = series.fillna(method='ffill').fillna(series.mean())\n",
        "    \n",
        "    try:\n",
        "        decomposition = seasonal_decompose(series, period=period, model='additive')\n",
        "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 8))\n",
        "        ax1.plot(series.index, series, label='Original'); ax1.legend(loc='upper left')\n",
        "        ax2.plot(series.index, decomposition.trend, label='Trend'); ax2.legend(loc='upper left')\n",
        "        ax3.plot(series.index, decomposition.seasonal, label='Seasonal'); ax3.legend(loc='upper left')\n",
        "        ax4.plot(series.index, decomposition.resid, label='Residual'); ax4.legend(loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "        logger.info(f\"Saved decomposition plot: {filename}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving decomposition plot: {str(e)}\")\n",
        "    finally:\n",
        "        plt.close()\n",
        "\n",
        "def plot_forecast(historical, test, forecast, forecast_index, title, ylabel, filename, confidence_intervals=None, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(historical.index, historical, label='Historical', color='blue')\n",
        "    ax.plot(test.index, test, label='Actual (Test)', color='green')\n",
        "    ax.plot(forecast_index, forecast, label='Forecast', color='orange', linestyle='--', linewidth=2)\n",
        "    if confidence_intervals:\n",
        "        ax.fill_between(forecast_index, confidence_intervals[0], confidence_intervals[1], \n",
        "                        color='orange', alpha=0.2, label='95% CI')\n",
        "    ax.set_title(title); ax.set_xlabel('Time'); ax.set_ylabel(ylabel); ax.legend(); ax.grid(True)\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
        "    plt.xticks(rotation=45); plt.tight_layout()\n",
        "    try:\n",
        "        plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "        logger.info(f\"Saved plot: {filename}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving plot: {str(e)}\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_comparison_forecasts(historical, test, forecasts, forecast_index, title, ylabel, filename, metrics=None, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "    ax.plot(historical.index, historical, label='Historical', color='blue')\n",
        "    ax.plot(test.index, test, label='Actual (Test)', color='green')\n",
        "    colors = sns.color_palette(\"husl\", len(forecasts))\n",
        "    for (model_name, forecast), color in zip(forecasts.items(), colors):\n",
        "        rmse = metrics.get(model_name, {}).get('RMSE', np.nan) if metrics else np.nan\n",
        "        if forecast is None or pd.isna(rmse):\n",
        "            continue\n",
        "        ax.plot(forecast_index, forecast, label=f'Forecast {model_name} (RMSE: {rmse:.4f})', \n",
        "                linestyle='--', color=color)\n",
        "    ax.set_title(title); ax.set_xlabel('Time'); ax.set_ylabel(ylabel); ax.legend(); ax.grid(True)\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
        "    plt.xticks(rotation=45); plt.tight_layout()\n",
        "    try:\n",
        "        plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "        logger.info(f\"Saved comparison plot: {filename}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving comparison plot: {str(e)}\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_bar(metrics_df, filename, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "    metrics = ['RMSE', 'MAE', 'MAPE', 'sMAPE', 'NormMAPE', 'DirAcc']\n",
        "    for i, (metric, ax) in enumerate(zip(metrics, axes.flatten())):\n",
        "        sns.barplot(x='Model', y=metric, data=metrics_df, ax=ax)\n",
        "        ax.set_title(f'{metric} Comparison')\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "    plt.tight_layout()\n",
        "    try:\n",
        "        plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "        logger.info(f\"Saved metrics bar plot: {filename}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving metrics bar plot: {str(e)}\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_residual_acf(residuals, title, filename, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    if residuals is None or len(residuals) < 2:\n",
        "        logger.warning(f\"Skipping ACF: Insufficient residual data - {title}\")\n",
        "        return\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "    max_lags = min(20, len(residuals) - 1)\n",
        "    if max_lags < 1:\n",
        "        return\n",
        "    try:\n",
        "        plot_acf(residuals, lags=max_lags, title=title, ax=ax)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "        logger.info(f\"Saved ACF plot: {filename}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving ACF plot: {str(e)}\")\n",
        "    plt.close()\n",
        "\n",
        "# Model Functions\n",
        "def run_exponential_smoothing(train, test, forecast_index, seasonal_periods=CONFIG['seasonal_periods']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        model = ExponentialSmoothing(train, trend='add', seasonal='add', \n",
        "                                  seasonal_periods=seasonal_periods).fit(optimized=True)\n",
        "        forecast = model.forecast(CONFIG['forecast_horizon'])\n",
        "        residuals = train - model.fittedvalues\n",
        "        forecast = pd.Series(forecast.values, index=forecast_index)\n",
        "        resid_std = np.std(residuals)\n",
        "        ci_lower = forecast - 1.96 * resid_std\n",
        "        ci_upper = forecast + 1.96 * resid_std\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"Exponential Smoothing: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, (ci_lower, ci_upper)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error Exponential Smoothing: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_sarima(train, test, forecast_index, seasonal_periods=CONFIG['seasonal_periods']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        d = check_stationarity(train, \"SARIMA\")\n",
        "        try:\n",
        "            model = pm.auto_arima(train, start_p=0, start_q=0, max_p=5, max_q=5, d=d, max_d=1,\n",
        "                                seasonal=True, m=seasonal_periods, start_P=0, start_Q=0, max_P=3, max_Q=3, max_D=3,\n",
        "                                stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
        "                                information_criterion='aic', maxiter=30)\n",
        "        except:\n",
        "            logger.warning(\"auto_arima failed, using SARIMA(1,1,1)(1,1,1,12)\")\n",
        "            model = pm.ARIMA(order=(1,1,1), seasonal_order=(1,1,1,seasonal_periods), \n",
        "                           suppress_warnings=True).fit(train)\n",
        "        forecast = model.predict(n_periods=CONFIG['forecast_horizon'])\n",
        "        residuals = train - model.predict_in_sample()\n",
        "        forecast = pd.Series(forecast, index=forecast_index)\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"SARIMA: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error SARIMA: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_prophet(train, test, forecast_index):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        df_train = pd.DataFrame({'ds': train.index, 'y': train.values})\n",
        "        model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False,\n",
        "                       changepoint_prior_scale=0.01, n_changepoints=10, seasonality_prior_scale=10.0).fit(df_train)\n",
        "        future = pd.DataFrame({'ds': forecast_index})\n",
        "        forecast = model.predict(future)\n",
        "        forecast_series = pd.Series(forecast['yhat'].values, index=forecast_index)\n",
        "        residuals = train - model.predict(df_train)['yhat']\n",
        "        ci_lower = pd.Series(forecast['yhat_lower'].values, index=forecast_index)\n",
        "        ci_upper = pd.Series(forecast['yhat_upper'].values, index=forecast_index)\n",
        "        metrics = calculate_metrics(test, forecast_series)\n",
        "        logger.info(f\"Prophet: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast_series, residuals, metrics, (ci_lower, ci_upper)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error Prophet: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "# Model Execution Pipeline\n",
        "def run_model_for_target(target, train, test, forecast_index, model_name, model_func, params, config=CONFIG):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(f\"Running {model_name} for {target}\")\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        forecast, residuals, (rmse, mae, mape, smape, norm_mape, dir_acc), ci = model_func(\n",
        "            train[target], test[target], forecast_index, **params\n",
        "        )\n",
        "        if forecast is None or pd.isna(rmse):\n",
        "            logger.error(f\"{model_name} for {target} failed to produce valid forecast or RMSE\")\n",
        "            return None\n",
        "        \n",
        "        plot_forecast(\n",
        "            train[target][-36:], test[target], forecast, forecast_index,\n",
        "            f'{model_name} Forecast for {target}', target, f'{target}_{model_name}_forecast.png', ci\n",
        "        )\n",
        "        if residuals is not None:\n",
        "            plot_residual_acf(\n",
        "                residuals.dropna(), f'ACF of Residuals - {model_name} ({target})',\n",
        "                f'{target}_{model_name}_acf.png'\n",
        "            )\n",
        "        \n",
        "        logger.info(f\"Completed {model_name} for {target} in {time.time() - start_time:.2f}s\")\n",
        "        return {\n",
        "            'Target': target,\n",
        "            'Model': model_name,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'MAPE': mape,\n",
        "            'sMAPE': smape,\n",
        "            'NormMAPE': norm_mape,\n",
        "            'DirAcc': dir_acc,\n",
        "            'Forecast': forecast,\n",
        "            'Residuals': residuals,\n",
        "            'CI': ci\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error running {model_name} for {target}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    logger = setup_logging(CONFIG['img_dir'])\n",
        "    try:\n",
        "        # Load dữ liệu với usecols để giảm bộ nhớ\n",
        "        cpi_data = pd.read_csv('data/cpi.csv', usecols=['t', 'cpi'])\n",
        "        cpi_data.rename(columns={'t': 'date'}, inplace=True)\n",
        "        cpi_data['time'] = pd.to_datetime(cpi_data['date'], format='%b-%y')\n",
        "        cpi_data.set_index('time', inplace=True)\n",
        "        cpi_data['cpi_mom'] = cpi_data['cpi'].pct_change() * 100\n",
        "        cpi_data = cpi_data[['cpi_mom']].dropna()  # Loại bỏ NaN ngay sau khi tạo cpi_mom\n",
        "\n",
        "        exog_data = pd.read_csv('data/exog_data.csv')\n",
        "        exog_data['Ngày'] = pd.to_datetime(exog_data['Ngày'])\n",
        "        exog_data.set_index('Ngày', inplace=True)\n",
        "\n",
        "        # Join và xử lý NaN một lần\n",
        "        data = cpi_data.join(exog_data, how='inner')\n",
        "        if data.isna().any().any():\n",
        "            logger.warning(\"Data contains NaN after join, filling...\")\n",
        "            data = data.fillna(method='ffill').fillna(data.mean(numeric_only=True))\n",
        "\n",
        "        # Tạo features\n",
        "        data_features = create_features(data, 'cpi_mom')\n",
        "        \n",
        "        # Split data\n",
        "        train_size = len(data) - CONFIG['forecast_horizon']\n",
        "        train, test = data_features[:train_size], data_features[train_size:]\n",
        "        forecast_index = pd.date_range(start=test.index[0], periods=CONFIG['forecast_horizon'], freq='MS')\n",
        "        \n",
        "        # Plot decomposition\n",
        "        plot_decomposition(data['cpi_mom'], period=CONFIG['seasonal_periods'], \n",
        "                         filename='cpi_mom_decomposition.png')\n",
        "        \n",
        "        # Define models\n",
        "        models = {\n",
        "            'Exponential Smoothing': (run_exponential_smoothing, {}),\n",
        "            'SARIMA': (run_sarima, {}),\n",
        "            'Prophet': (run_prophet, {})\n",
        "        }\n",
        "        \n",
        "        # Run models in parallel\n",
        "        results = []\n",
        "        forecasts_mom = {}\n",
        "        metrics_mom = {}\n",
        "        logger.info(\"Running models for cpi_mom\")\n",
        "        \n",
        "        tasks = [\n",
        "            delayed(run_model_for_target)(\n",
        "                'cpi_mom', train, test, forecast_index, model_name, model_func, params\n",
        "            ) for model_name, (model_func, params) in models.items()\n",
        "        ]\n",
        "        model_results = Parallel(n_jobs=CONFIG['n_jobs'], verbose=1, backend='loky')(tasks)\n",
        "        \n",
        "        # Process results\n",
        "        for result in model_results:\n",
        "            if result is not None:\n",
        "                results.append({\n",
        "                    'Target': result['Target'],\n",
        "                    'Model': result['Model'],\n",
        "                    'RMSE': result['RMSE'],\n",
        "                    'MAE': result['MAE'],\n",
        "                    'MAPE': result['MAPE'],\n",
        "                    'sMAPE': result['sMAPE'],\n",
        "                    'NormMAPE': result['NormMAPE'],\n",
        "                    'DirAcc': result['DirAcc']\n",
        "                })\n",
        "                forecasts_mom[result['Model']] = result['Forecast']\n",
        "                metrics_mom[result['Model']] = {'RMSE': result['RMSE']}\n",
        "        \n",
        "        # Generate comparison plots and save results\n",
        "        if forecasts_mom:\n",
        "            plot_comparison_forecasts(\n",
        "                train['cpi_mom'][-36:], test['cpi_mom'], forecasts_mom, forecast_index,\n",
        "                'Comparison of Forecasts for cpi_mom', 'cpi_mom', \n",
        "                'cpi_mom_model_comparison.png', metrics=metrics_mom\n",
        "            )\n",
        "        \n",
        "        results_df = pd.DataFrame(results)\n",
        "        if not results_df.empty:\n",
        "            print(results_df)\n",
        "            results_df.to_csv(CONFIG['results_file'], index=False)\n",
        "            logger.info(f\"Results saved to {CONFIG['results_file']}\")\n",
        "            plot_metrics_bar(results_df, 'cpi_mom_metrics_comparison.png')\n",
        "        \n",
        "        if forecasts_mom:\n",
        "            combined_forecast = pd.DataFrame({'Date': forecast_index})\n",
        "            for model_name, forecast in forecasts_mom.items():\n",
        "                combined_forecast[f'{model_name}_cpi_mom'] = forecast\n",
        "            combined_forecast.to_csv(f'{CONFIG[\"img_dir\"]}/combined_forecast_cpi_mom.csv', index=False)\n",
        "            logger.info(f\"Combined forecasts saved to {CONFIG['img_dir']}/combined_forecast_cpi_mom.csv\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Main program error: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1f379a5e-6705-48c9-ba5b-f93e5ea97a7b",
        "b305be36-e6cb-44ce-8b82-9cbdd8838dba"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
