{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9fae4869",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\anaconda3\\envs\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done 8 out of 8 | elapsed: 11.5min finished\n",
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done 1 out of 1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=4)]: Done 3 out of 3 | elapsed:    0.6s finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Target                  Model      RMSE       MAE        MAPE       sMAPE  \\\n",
            "0  cpi_mom  Exponential Smoothing  0.319763  0.285126  256.581561  140.962257   \n",
            "1  cpi_mom                 SARIMA  0.325483  0.286272  252.902619  137.211988   \n",
            "2  cpi_mom                Prophet  0.300574  0.250898  231.055562  119.815358   \n",
            "3  cpi_mom                XGBoost  0.291215  0.258049  221.849376  132.195043   \n",
            "4  cpi_mom               LightGBM  0.261888  0.205114   93.970002   97.258134   \n",
            "5  cpi_mom                    SVR  0.194838  0.143999  126.863913   80.239780   \n",
            "6  cpi_mom                   LSTM  0.476645  0.353113  115.392848  169.933539   \n",
            "7  cpi_mom                    GRU  0.499680  0.405019  196.234463  170.683812   \n",
            "8  cpi_mom      Weighted Ensemble  0.236918  0.198847  101.444213  121.136437   \n",
            "\n",
            "     NormMAPE     DirAcc  \n",
            "0  752.574411  36.363636  \n",
            "1  741.783777  36.363636  \n",
            "2  677.704598  54.545455  \n",
            "3  650.702111  72.727273  \n",
            "4  275.621595  81.818182  \n",
            "5  372.102087  81.818182  \n",
            "6  338.456530  63.636364  \n",
            "7  575.571507  54.545455  \n",
            "8  297.544058  72.727273  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import pmdarima as pm\n",
        "from prophet import Prophet\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from joblib import Parallel, delayed\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "\n",
        "# Configuration\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "\n",
        "CONFIG = {\n",
        "    'forecast_horizon': 12,\n",
        "    'seasonal_periods': 12,\n",
        "    'min_data_length': 24,\n",
        "    'img_dir': 'model_results',\n",
        "    'results_file': 'model_results/model_results.csv',\n",
        "    'n_jobs': 4,\n",
        "    'outlier_threshold': 3,\n",
        "    'max_diff': 3,\n",
        "    'lag_features': list(range(1, 13)),\n",
        "    'rolling_windows': [3, 6, 12],\n",
        "    'correlation_threshold': 0.2,\n",
        "    'dpi': 150,\n",
        "    'sequence_length': 12, \n",
        "    'batch_size': 8,\n",
        "    'epochs': 5,\n",
        "}\n",
        "\n",
        "# Setup logging\n",
        "def setup_logging(img_dir):\n",
        "    os.makedirs(img_dir, exist_ok=True)\n",
        "    logging.basicConfig(\n",
        "        filename=f'{img_dir}/forecast_log.txt',\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "    return logging.getLogger(__name__)\n",
        "\n",
        "# Outlier Detection\n",
        "def detect_outliers(series, threshold=CONFIG['outlier_threshold']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    z_scores = np.abs((series - series.mean()) / series.std())\n",
        "    outliers = z_scores > threshold\n",
        "    series_clean = series.copy()\n",
        "    # series_clean[outliers] = series.mean()\n",
        "    logger.info(f\"Detected {outliers.sum()} outliers\")\n",
        "    return series_clean\n",
        "\n",
        "# Feature Engineering\n",
        "def create_features(data, target, exog_cols, config=CONFIG):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(f\"Creating features for {target}, data shape: {data.shape}\")\n",
        "    \n",
        "    if len(data) < config['min_data_length']:\n",
        "        raise ValueError(f\"Data too short: {len(data)} rows\")\n",
        "    if not isinstance(data.index, pd.DatetimeIndex):\n",
        "        raise ValueError(\"DataFrame index must be DatetimeIndex\")\n",
        "    \n",
        "    if target not in data.columns:\n",
        "        raise ValueError(f\"Target column {target} not found in data\")\n",
        "    \n",
        "    df = data.copy()\n",
        "    required_cols = [target] + exog_cols\n",
        "    \n",
        "    # Handle missing/infinite values\n",
        "    if df.isna().any().any() or np.isinf(df).any().any():\n",
        "        logger.warning(\"Data contains NaN or Inf, filling...\")\n",
        "        df = df.fillna(method='ffill').fillna(df.mean(numeric_only=True))\n",
        "    \n",
        "    # Vectorized lag and rolling features\n",
        "    lag_features = {f'{target}_lag_{lag}': df[target].shift(lag) for lag in config['lag_features']}\n",
        "    rolling_features = {\n",
        "        f'{target}_roll_{stat}_{window}': getattr(df[target].rolling(window=window), stat)()\n",
        "        for window in config['rolling_windows']\n",
        "        for stat in ['mean', 'std']\n",
        "    }\n",
        "    df = df.assign(**lag_features, **rolling_features)\n",
        "    \n",
        "    # Add seasonal features\n",
        "    df = df.assign(\n",
        "        month=df.index.month,\n",
        "        month_sin=np.sin(2 * np.pi * df.index.month / config['seasonal_periods']),\n",
        "        month_cos=np.cos(2 * np.pi * df.index.month / config['seasonal_periods']),\n",
        "        quarter=df.index.quarter\n",
        "    )\n",
        "    df = pd.get_dummies(df, columns=['month'], prefix='month')\n",
        "    \n",
        "    # Remove low-correlation features\n",
        "    try:\n",
        "        correlations = df.corr(numeric_only=True)[target].drop(required_cols, errors='ignore')\n",
        "        low_corr_cols = correlations[abs(correlations) < config['correlation_threshold']].index\n",
        "        logger.info(f\"Low-correlation features: {list(low_corr_cols)}\")\n",
        "        if low_corr_cols.any():\n",
        "            logger.info(f\"Dropping {len(low_corr_cols)} low-correlation features\")\n",
        "            df = df.drop(columns=low_corr_cols)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error calculating correlations: {str(e)}\")\n",
        "    \n",
        "    # Kiểm tra NaN sau khi tạo features\n",
        "    if df.isna().any().any() or np.isinf(df).any().any():\n",
        "        logger.warning(\"NaN/Inf in features after creation, filling...\")\n",
        "        df = df.fillna(df.mean(numeric_only=True))\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Stationarity Check\n",
        "def check_stationarity(series, name, max_diff=CONFIG['max_diff']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    series_clean = series.dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
        "    if len(series_clean) < 2:\n",
        "        logger.error(f\"{name}: Data too short after cleaning!\")\n",
        "        return 0\n",
        "    \n",
        "    d = 0\n",
        "    while d <= max_diff:\n",
        "        result = adfuller(series_clean)\n",
        "        if result[1] < 0.05:\n",
        "            logger.info(f\"{name} stationary at d={d}\")\n",
        "            return d\n",
        "        if d == max_diff:\n",
        "            logger.warning(f\"{name} not stationary after {max_diff} differencing\")\n",
        "            return d\n",
        "        series_clean = series_clean.diff().dropna()\n",
        "        if len(series_clean) < 2:\n",
        "            logger.warning(f\"{name}: Data too short after differencing {d+1}\")\n",
        "            return d\n",
        "        d += 1\n",
        "    return d\n",
        "\n",
        "# Model Evaluation Metrics\n",
        "def calculate_metrics(actual, predicted):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    actual = np.array(actual, dtype=float)\n",
        "    predicted = np.array(predicted, dtype=float)\n",
        "    valid_mask = ~np.isnan(actual) & ~np.isnan(predicted) & ~np.isinf(actual) & ~np.isinf(predicted)\n",
        "    actual = actual[valid_mask]\n",
        "    predicted = predicted[valid_mask]\n",
        "    \n",
        "    if len(actual) == 0:\n",
        "        logger.warning(\"No valid data for metrics calculation!\")\n",
        "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    mape = mean_absolute_percentage_error(actual, predicted) * 100 if np.all(np.abs(actual) > 1e-8) else np.nan\n",
        "    smape = 100 * np.mean(2 * np.abs(predicted - actual) / (np.abs(actual) + np.abs(predicted)))\n",
        "    norm_mape = mape / np.mean(np.abs(actual)) if not np.isnan(mape) else np.nan\n",
        "    directional_acc = np.mean((np.diff(actual) * np.diff(predicted)) > 0) * 100 if len(actual) > 1 else np.nan\n",
        "    return rmse, mae, mape, smape, norm_mape, directional_acc\n",
        "\n",
        "# Visualization Functions\n",
        "def plot_decomposition(series, period, filename, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    if series.isna().any():\n",
        "        series = series.fillna(method='ffill').fillna(series.mean())\n",
        "    \n",
        "    try:\n",
        "        decomposition = seasonal_decompose(series, period=period, model='additive')\n",
        "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 8))\n",
        "        ax1.plot(series.index, series, label='Original'); ax1.legend(loc='upper left')\n",
        "        ax2.plot(series.index, decomposition.trend, label='Trend'); ax2.legend(loc='upper left')\n",
        "        ax3.plot(series.index, decomposition.seasonal, label='Seasonal'); ax3.legend(loc='upper left')\n",
        "        ax4.plot(series.index, decomposition.resid, label='Residual'); ax4.legend(loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "        logger.info(f\"Saved decomposition plot: {filename}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving decomposition plot: {str(e)}\")\n",
        "    finally:\n",
        "        plt.close()\n",
        "\n",
        "def plot_forecast(historical, test, forecast, forecast_index, title, ylabel, filename, confidence_intervals=None, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(historical.index, historical, label='Historical', color='blue')\n",
        "    ax.plot(test.index, test, label='Actual (Test)', color='green')\n",
        "    ax.plot(forecast_index, forecast, label='Forecast', color='orange', linestyle='--', linewidth=2)\n",
        "    if confidence_intervals:\n",
        "        ax.fill_between(forecast_index, confidence_intervals[0], confidence_intervals[1], \n",
        "                        color='orange', alpha=0.2, label='95% CI')\n",
        "    ax.set_title(title); ax.set_xlabel('Time'); ax.set_ylabel(ylabel); ax.legend(); ax.grid(True)\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
        "    plt.xticks(rotation=45); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "    plt.close()\n",
        "\n",
        "def plot_comparison_forecasts(historical, test, forecasts, forecast_index, title, ylabel, filename, metrics=None, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    fig, ax = plt.subplots(figsize=(14, 8))\n",
        "    ax.plot(historical.index, historical, label='Historical', color='blue')\n",
        "    ax.plot(test.index, test, label='Actual (Test)', color='green')\n",
        "    colors = sns.color_palette(\"husl\", len(forecasts))\n",
        "    for (model_name, forecast), color in zip(forecasts.items(), colors):\n",
        "        rmse = metrics.get(model_name, {}).get('RMSE', np.nan) if metrics else np.nan\n",
        "        if forecast is None or pd.isna(rmse):\n",
        "            continue\n",
        "        ax.plot(forecast_index, forecast, label=f'{model_name} (RMSE: {rmse:.4f})', \n",
        "                linestyle='--', color=color)\n",
        "    ax.set_title(title); ax.set_xlabel('Time'); ax.set_ylabel(ylabel); ax.legend(); ax.grid(True)\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
        "    plt.xticks(rotation=45); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "    plt.close()\n",
        "\n",
        "def plot_metrics_bar(metrics_df, filename, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "    metrics = ['RMSE', 'MAE', 'MAPE', 'sMAPE', 'NormMAPE', 'DirAcc']\n",
        "    for i, (metric, ax) in enumerate(zip(metrics, axes.flatten())):\n",
        "        sns.barplot(x='Model', y=metric, data=metrics_df, ax=ax)\n",
        "        ax.set_title(f'{metric} Comparison')\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "    plt.close()\n",
        "\n",
        "def plot_residual_acf(residuals, title, filename, img_dir=CONFIG['img_dir']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    if residuals is None or len(residuals) < 2:\n",
        "        logger.warning(f\"Skipping ACF: Insufficient residual data - {title}\")\n",
        "        return\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "    max_lags = min(20, len(residuals) - 1)\n",
        "    if max_lags < 1:\n",
        "        return\n",
        "    plot_acf(residuals, lags=max_lags, title=title, ax=ax)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(img_dir, filename), dpi=CONFIG['dpi'])\n",
        "    plt.close()\n",
        "\n",
        "# Sequence Creation for LSTM/GRU\n",
        "def create_sequences(data, seq_length, target_col):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    data = data.copy()\n",
        "    if data.isna().any().any():\n",
        "        logger.warning(\"Data contains NaN in create_sequences, filling...\")\n",
        "        data = data.fillna(data.mean(numeric_only=True))\n",
        "    if np.isinf(data).any().any():\n",
        "        logger.warning(\"Data contains Inf in create_sequences, replacing...\")\n",
        "        data = data.replace([np.inf, -np.inf], data.mean(numeric_only=True))\n",
        "    \n",
        "    logger.info(f\"Data head in create_sequences:\\n{data.head()}\")\n",
        "    X, y = [], []\n",
        "    if len(data) < seq_length + 1:\n",
        "        logger.error(f\"Data too short for sequence length {seq_length}: {len(data)}\")\n",
        "        return np.array([]), np.array([])\n",
        "    \n",
        "    for i in range(len(data) - seq_length):\n",
        "        seq = data.iloc[i:i+seq_length][[target_col]].values\n",
        "        if np.isnan(seq).any() or np.isinf(seq).any():\n",
        "            logger.warning(f\"NaN/Inf in sequence {i}, skipping...\")\n",
        "            continue\n",
        "        X.append(seq)\n",
        "        y.append(data.iloc[i+seq_length][target_col])\n",
        "    \n",
        "    X = np.array(X, dtype=np.float32)\n",
        "    y = np.array(y, dtype=np.float32)\n",
        "    if X.shape[0] == 0:\n",
        "        logger.error(\"No valid sequences created\")\n",
        "    else:\n",
        "        logger.info(f\"Created {X.shape[0]} sequences with shape {X.shape}\")\n",
        "    return X, y\n",
        "\n",
        "# Model Functions\n",
        "def run_exponential_smoothing(train, test, forecast_index, seasonal_periods=CONFIG['seasonal_periods']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        model = ExponentialSmoothing(train, trend='add', seasonal='add', \n",
        "                                  seasonal_periods=seasonal_periods).fit(optimized=True)\n",
        "        forecast = model.forecast(CONFIG['forecast_horizon'])\n",
        "        residuals = train - model.fittedvalues\n",
        "        forecast = pd.Series(forecast.values, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"Exponential Smoothing forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        resid_std = np.std(residuals)\n",
        "        ci_lower = forecast - 1.96 * resid_std\n",
        "        ci_upper = forecast + 1.96 * resid_std\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"Exponential Smoothing: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, (ci_lower, ci_upper)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error Exponential Smoothing: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_sarima(train, test, forecast_index, exog_train=None, exog_test=None, seasonal_periods=CONFIG['seasonal_periods']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        if exog_train is not None and exog_test is not None:\n",
        "            exog_train = exog_train.fillna(exog_train.mean(numeric_only=True))\n",
        "            exog_test = exog_test.fillna(exog_test.mean(numeric_only=True))\n",
        "            if len(exog_test) < CONFIG['forecast_horizon']:\n",
        "                logger.error(f\"Exogenous test data too short: {len(exog_test)} < {CONFIG['forecast_horizon']}\")\n",
        "                return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        d = check_stationarity(train, \"SARIMA\")\n",
        "        try:\n",
        "            model = pm.auto_arima(train, exogenous=exog_train, start_p=0, start_q=0, max_p=5, max_q=5, d=d, max_d=1,\n",
        "                                seasonal=True, m=seasonal_periods, start_P=0, start_Q=0, max_P=3, max_Q=3, max_D=1,\n",
        "                                stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
        "                                information_criterion='aic', maxiter=30)\n",
        "        except:\n",
        "            logger.warning(\"auto_arima failed, using SARIMA(1,1,1)(1,1,1,12)\")\n",
        "            model = pm.ARIMA(order=(1,1,1), seasonal_order=(1,1,1,seasonal_periods), \n",
        "                           suppress_warnings=True).fit(train, exogenous=exog_train)\n",
        "        forecast = model.predict(n_periods=CONFIG['forecast_horizon'], exogenous=exog_test)\n",
        "        residuals = train - model.predict_in_sample(exogenous=exog_train)\n",
        "        forecast = pd.Series(forecast, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"SARIMA forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"SARIMA: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error SARIMA: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_prophet(train, test, forecast_index, exog_train=None, exog_future=None):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        df_train = pd.DataFrame({'ds': train.index, 'y': train.values})\n",
        "        if exog_train is not None:\n",
        "            for col in exog_train.columns:\n",
        "                df_train[col] = exog_train[col].values\n",
        "        if exog_future is not None:\n",
        "            exog_future = exog_future.fillna(exog_future.mean(numeric_only=True))\n",
        "            if len(exog_future) < CONFIG['forecast_horizon']:\n",
        "                logger.error(f\"Exogenous future data too short: {len(exog_future)} < {CONFIG['forecast_horizon']}\")\n",
        "                return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False,\n",
        "                       changepoint_prior_scale=0.01, n_changepoints=10, seasonality_prior_scale=10.0)\n",
        "        if exog_train is not None:\n",
        "            for col in exog_train.columns:\n",
        "                model.add_regressor(col)\n",
        "        model.fit(df_train)\n",
        "        future = pd.DataFrame({'ds': forecast_index})\n",
        "        if exog_future is not None:\n",
        "            for col in exog_future.columns:\n",
        "                future[col] = exog_future[col].values\n",
        "        forecast = model.predict(future)\n",
        "        forecast_series = pd.Series(forecast['yhat'].values, index=forecast_index)\n",
        "        if len(forecast_series) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"Prophet forecast length {len(forecast_series)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        residuals = train - model.predict(df_train)['yhat']\n",
        "        ci_lower = pd.Series(forecast['yhat_lower'].values, index=forecast_index)\n",
        "        ci_upper = pd.Series(forecast['yhat_upper'].values, index=forecast_index)\n",
        "        metrics = calculate_metrics(test, forecast_series)\n",
        "        logger.info(f\"Prophet: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast_series, residuals, metrics, (ci_lower, ci_upper)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error Prophet: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_xgboost(train, test, forecast_index, train_X, test_X):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        if train_X.isna().any().any() or test_X.isna().any().any():\n",
        "            logger.warning(\"NaN in train_X or test_X, filling...\")\n",
        "            train_X = train_X.fillna(train_X.mean(numeric_only=True))\n",
        "            test_X = test_X.fillna(test_X.mean(numeric_only=True))\n",
        "        if np.isinf(train_X).any().any() or np.isinf(test_X).any().any():\n",
        "            logger.warning(\"Inf in train_X or test_X, replacing...\")\n",
        "            train_X = train_X.replace([np.inf, -np.inf], train_X.mean(numeric_only=True))\n",
        "            test_X = test_X.replace([np.inf, -np.inf], test_X.mean(numeric_only=True))\n",
        "        if len(test_X) < CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"Test features too short: {len(test_X)} < {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "        model.fit(train_X, train)\n",
        "        forecast = model.predict(test_X)\n",
        "        residuals = train - model.predict(train_X)\n",
        "        forecast = pd.Series(forecast, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"XGBoost forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"XGBoost: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error XGBoost: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_lightgbm(train, test, forecast_index, train_X, test_X):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        if train_X.isna().any().any() or test_X.isna().any().any():\n",
        "            logger.warning(\"NaN in train_X or test_X, filling...\")\n",
        "            train_X = train_X.fillna(train_X.mean(numeric_only=True))\n",
        "            test_X = test_X.fillna(test_X.mean(numeric_only=True))\n",
        "        if np.isinf(train_X).any().any() or np.isinf(test_X).any().any():\n",
        "            logger.warning(\"Inf in train_X or test_X, replacing...\")\n",
        "            train_X = train_X.replace([np.inf, -np.inf], train_X.mean(numeric_only=True))\n",
        "            test_X = test_X.replace([np.inf, -np.inf], test_X.mean(numeric_only=True))\n",
        "        if len(test_X) < CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"Test features too short: {len(test_X)} < {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        model = LGBMRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "        model.fit(train_X, train)\n",
        "        forecast = model.predict(test_X)\n",
        "        residuals = train - model.predict(train_X)\n",
        "        forecast = pd.Series(forecast, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"LightGBM forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"LightGBM: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error LightGBM: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_svr(train, test, forecast_index, train_X, test_X):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        if train_X.isna().any().any() or test_X.isna().any().any():\n",
        "            logger.warning(\"NaN in train_X or test_X, filling...\")\n",
        "            train_X = train_X.fillna(train_X.mean(numeric_only=True))\n",
        "            test_X = test_X.fillna(test_X.mean(numeric_only=True))\n",
        "        if np.isinf(train_X).any().any() or np.isinf(test_X).any().any():\n",
        "            logger.warning(\"Inf in train_X or test_X, replacing...\")\n",
        "            train_X = train_X.replace([np.inf, -np.inf], train_X.mean(numeric_only=True))\n",
        "            test_X = test_X.replace([np.inf, -np.inf], test_X.mean(numeric_only=True))\n",
        "        if len(test_X) < CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"Test features too short: {len(test_X)} < {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        model = SVR(C=1, epsilon=0.1, kernel='rbf')\n",
        "        scaler = MinMaxScaler()\n",
        "        train_X_scaled = scaler.fit_transform(train_X)\n",
        "        test_X_scaled = scaler.transform(test_X)\n",
        "        if np.isnan(train_X_scaled).any() or np.isnan(test_X_scaled).any():\n",
        "            logger.error(\"NaN in scaled data for SVR\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        model.fit(train_X_scaled, train)\n",
        "        forecast = model.predict(test_X_scaled)\n",
        "        residuals = train - model.predict(train_X_scaled)\n",
        "        forecast = pd.Series(forecast, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"SVR forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"SVR: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error SVR: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_lstm(train, test, forecast_index, train_X, test_X, seq_length=CONFIG['sequence_length']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        # Chỉ sử dụng target (cpi_mom) để đơn giản hóa\n",
        "        combined_data = pd.DataFrame({\n",
        "            'target': pd.concat([train, test], axis=0)\n",
        "        })\n",
        "        logger.info(f\"LSTM: combined_data shape: {combined_data.shape}\")\n",
        "        logger.info(f\"LSTM: combined_data head:\\n{combined_data.head()}\")\n",
        "        \n",
        "        if combined_data.isna().any().any() or np.isinf(combined_data).any().any():\n",
        "            logger.warning(\"NaN/Inf in combined_data, filling...\")\n",
        "            combined_data = combined_data.fillna(combined_data.mean(numeric_only=True))\n",
        "        \n",
        "        scaler = MinMaxScaler()\n",
        "        combined_scaled = scaler.fit_transform(combined_data)\n",
        "        if np.isnan(combined_scaled).any() or np.isinf(combined_scaled).any():\n",
        "            logger.error(\"NaN/Inf in scaled data for LSTM\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        \n",
        "        combined_scaled_df = pd.DataFrame(combined_scaled, index=combined_data.index, \n",
        "                                        columns=['target'])\n",
        "        \n",
        "        X_seq, y_seq = create_sequences(combined_scaled_df, seq_length, 'target')\n",
        "        if X_seq.shape[0] == 0:\n",
        "            logger.error(\"Failed to create sequences for LSTM\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        \n",
        "        train_seq_len = len(train) - seq_length\n",
        "        if train_seq_len <= 0:\n",
        "            logger.error(f\"Train sequence length too short: {train_seq_len}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        X_train_seq, y_train_seq = X_seq[:train_seq_len], y_seq[:train_seq_len]\n",
        "        X_test_seq, y_test_seq = X_seq[train_seq_len:], y_seq[train_seq_len:]\n",
        "        logger.info(f\"LSTM: X_train_seq shape {X_train_seq.shape}, X_test_seq shape {X_test_seq.shape}\")\n",
        "        \n",
        "        model = Sequential([\n",
        "            LSTM(32, activation='relu', input_shape=(seq_length, 1)),\n",
        "            Dropout(0.2),\n",
        "            Dense(1)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        model.fit(X_train_seq, y_train_seq, epochs=CONFIG['epochs'], batch_size=CONFIG['batch_size'], verbose=0)\n",
        "        \n",
        "        # Recursive forecasting\n",
        "        forecast = []\n",
        "        input_seq = X_seq[train_seq_len - 1].copy()\n",
        "        for i in range(CONFIG['forecast_horizon']):\n",
        "            input_seq_reshaped = input_seq.reshape((1, seq_length, 1))\n",
        "            pred = model.predict(input_seq_reshaped, verbose=0)[0, 0]\n",
        "            forecast.append(pred)\n",
        "            input_seq = np.roll(input_seq, -1, axis=0)\n",
        "            input_seq[-1] = pred\n",
        "        \n",
        "        forecast_unscaled = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()\n",
        "        residuals = train.iloc[seq_length:] - scaler.inverse_transform(\n",
        "            model.predict(X_train_seq)[:, 0].reshape(-1, 1)\n",
        "        ).flatten()\n",
        "        forecast = pd.Series(forecast_unscaled, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"LSTM forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"LSTM: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error LSTM: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_gru(train, test, forecast_index, train_X, test_X, seq_length=CONFIG['sequence_length']):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        # Chỉ sử dụng target (cpi_mom) để đơn giản hóa\n",
        "        combined_data = pd.DataFrame({\n",
        "            'target': pd.concat([train, test], axis=0)\n",
        "        })\n",
        "        logger.info(f\"GRU: combined_data shape: {combined_data.shape}\")\n",
        "        logger.info(f\"GRU: combined_data head:\\n{combined_data.head()}\")\n",
        "        \n",
        "        if combined_data.isna().any().any() or np.isinf(combined_data).any().any():\n",
        "            logger.warning(\"NaN/Inf in combined_data, filling...\")\n",
        "            combined_data = combined_data.fillna(combined_data.mean(numeric_only=True))\n",
        "        \n",
        "        scaler = MinMaxScaler()\n",
        "        combined_scaled = scaler.fit_transform(combined_data)\n",
        "        if np.isnan(combined_scaled).any() or np.isinf(combined_scaled).any():\n",
        "            logger.error(\"NaN/Inf in scaled data for GRU\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        \n",
        "        combined_scaled_df = pd.DataFrame(combined_scaled, index=combined_data.index, \n",
        "                                        columns=['target'])\n",
        "        \n",
        "        X_seq, y_seq = create_sequences(combined_scaled_df, seq_length, 'target')\n",
        "        if X_seq.shape[0] == 0:\n",
        "            logger.error(\"Failed to create sequences for GRU\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        \n",
        "        train_seq_len = len(train) - seq_length\n",
        "        if train_seq_len <= 0:\n",
        "            logger.error(f\"Train sequence length too short: {train_seq_len}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        X_train_seq, y_train_seq = X_seq[:train_seq_len], y_seq[:train_seq_len]\n",
        "        X_test_seq, y_test_seq = X_seq[train_seq_len:], y_seq[train_seq_len:]\n",
        "        logger.info(f\"GRU: X_train_seq shape {X_train_seq.shape}, X_test_seq shape {X_test_seq.shape}\")\n",
        "        \n",
        "        model = Sequential([\n",
        "            GRU(32, activation='relu', input_shape=(seq_length, 1)),\n",
        "            Dropout(0.2),\n",
        "            Dense(1)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        model.fit(X_train_seq, y_train_seq, epochs=CONFIG['epochs'], batch_size=CONFIG['batch_size'], verbose=0)\n",
        "        \n",
        "        # Recursive forecasting\n",
        "        forecast = []\n",
        "        input_seq = X_seq[train_seq_len - 1].copy()\n",
        "        for i in range(CONFIG['forecast_horizon']):\n",
        "            input_seq_reshaped = input_seq.reshape((1, seq_length, 1))\n",
        "            pred = model.predict(input_seq_reshaped, verbose=0)[0, 0]\n",
        "            forecast.append(pred)\n",
        "            input_seq = np.roll(input_seq, -1, axis=0)\n",
        "            input_seq[-1] = pred\n",
        "        \n",
        "        forecast_unscaled = scaler.inverse_transform(np.array(forecast).reshape(-1, 1)).flatten()\n",
        "        residuals = train.iloc[seq_length:] - scaler.inverse_transform(\n",
        "            model.predict(X_train_seq)[:, 0].reshape(-1, 1)\n",
        "        ).flatten()\n",
        "        forecast = pd.Series(forecast_unscaled, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"GRU forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"GRU: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error GRU: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_voting_ensemble(forecasts, test, forecast_index):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        valid_forecasts = [f for f in forecasts.values() if f is not None and not f.isna().any() and len(f) == CONFIG['forecast_horizon']]\n",
        "        if len(valid_forecasts) < 2:\n",
        "            logger.error(f\"Not enough valid forecasts for Voting Ensemble: {len(valid_forecasts)}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        logger.info(f\"Voting Ensemble using {len(valid_forecasts)} forecasts: {[k for k, f in forecasts.items() if f is not None and not f.isna().any() and len(f) == CONFIG['forecast_horizon']]}\")\n",
        "        forecast = pd.DataFrame(valid_forecasts).mean().values\n",
        "        forecast = pd.Series(forecast, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"Voting Ensemble forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        residuals = None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"Voting Ensemble: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error Voting Ensemble: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_weighted_ensemble(forecasts, test, forecast_index, metrics):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        valid_forecasts = {k: f for k, f in forecasts.items() if f is not None and not f.isna().any() and len(f) == CONFIG['forecast_horizon']}\n",
        "        valid_metrics = {k: m['RMSE'] for k, m in metrics.items() if m['RMSE'] is not np.nan}\n",
        "        valid_forecasts = {k: f for k, f in valid_forecasts.items() if k in valid_metrics}\n",
        "        if len(valid_forecasts) < 2:\n",
        "            logger.error(f\"Not enough valid forecasts for Weighted Ensemble: {len(valid_forecasts)}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        \n",
        "        logger.info(f\"Weighted Ensemble using {len(valid_forecasts)} forecasts: {list(valid_forecasts.keys())}\")\n",
        "        weights = {k: 1 / max(m, 1e-8) for k, m in valid_metrics.items()}\n",
        "        total_weight = sum(weights.values())\n",
        "        weights = {k: w / total_weight for k, w in weights.items()}\n",
        "        \n",
        "        forecast = sum(weights[k] * f for k, f in valid_forecasts.items())\n",
        "        forecast = pd.Series(forecast, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"Weighted Ensemble forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        residuals = None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"Weighted Ensemble: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error Weighted Ensemble: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "def run_stacking_ensemble(train, test, forecast_index, forecasts_train, forecasts_test):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        X_train = pd.DataFrame({k: f for k, f in forecasts_train.items() if f is not None and not f.isna().any()})\n",
        "        X_test = pd.DataFrame({k: f for k, f in forecasts_test.items() if f is not None and not f.isna().any() and len(f) == CONFIG['forecast_horizon']})\n",
        "        if X_train.empty or X_test.empty or len(X_train.columns) < 2:\n",
        "            logger.error(f\"Not enough valid forecasts for Stacking Ensemble: {len(X_train.columns)}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        \n",
        "        logger.info(f\"Stacking Ensemble using {len(X_train.columns)} forecasts: {list(X_train.columns)}\")\n",
        "        if X_train.isna().any().any() or X_test.isna().any().any():\n",
        "            logger.warning(\"NaN in forecasts_train or forecasts_test, filling...\")\n",
        "            X_train = X_train.fillna(X_train.mean(numeric_only=True))\n",
        "            X_test = X_test.fillna(X_test.mean(numeric_only=True))\n",
        "        \n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, train)\n",
        "        forecast = model.predict(X_test)\n",
        "        residuals = train - model.predict(X_train)\n",
        "        forecast = pd.Series(forecast, index=forecast_index)\n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"Stacking Ensemble forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "        metrics = calculate_metrics(test, forecast)\n",
        "        logger.info(f\"Stacking Ensemble: RMSE={metrics[0]:.4f}, Time={time.time() - start_time:.2f}s\")\n",
        "        return forecast, residuals, metrics, None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error Stacking Ensemble: {str(e)}\")\n",
        "        return None, None, (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan), None\n",
        "\n",
        "# Model Execution Pipeline\n",
        "def run_model_for_target(target, train, test, forecast_index, model_name, model_func, params, exog_cols, config=CONFIG):\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info(f\"Running {model_name} for {target}\")\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        if model_name in ['XGBoost', 'LightGBM', 'SVR']:\n",
        "            feature_cols = [c for c in train.columns if c != target and c in test.columns]\n",
        "            if not feature_cols:\n",
        "                logger.error(f\"No valid features for {model_name}\")\n",
        "                return None\n",
        "            train_X = train[feature_cols]\n",
        "            test_X = test[feature_cols]\n",
        "            logger.info(f\"{model_name}: train_X shape {train_X.shape}, test_X shape {test_X.shape}\")\n",
        "            forecast, residuals, metrics, ci = model_func(train[target], test[target], forecast_index, train_X, test_X)\n",
        "        elif model_name in ['LSTM', 'GRU']:\n",
        "            # Pass train_X, test_X for compatibility, but they are not used\n",
        "            train_X = train[[target]]\n",
        "            test_X = test[[target]]\n",
        "            logger.info(f\"{model_name}: train_X shape {train_X.shape}, test_X shape {test_X.shape}\")\n",
        "            forecast, residuals, metrics, ci = model_func(train[target], test[target], forecast_index, train_X, test_X)\n",
        "        elif model_name in ['SARIMA', 'Prophet']:\n",
        "            exog_train = train[exog_cols] if exog_cols else None\n",
        "            exog_test = test[exog_cols] if exog_cols else None\n",
        "            forecast, residuals, metrics, ci = model_func(train[target], test[target], forecast_index, exog_train, exog_test)\n",
        "        elif model_name in ['Voting Ensemble', 'Weighted Ensemble']:\n",
        "            forecast, residuals, metrics, ci = model_func(params['forecasts'], test[target], forecast_index, params.get('metrics', {}))\n",
        "        elif model_name == 'Stacking Ensemble':\n",
        "            forecast, residuals, metrics, ci = model_func(train[target], test[target], forecast_index, \n",
        "                                                        params['forecasts_train'], params['forecasts_test'])\n",
        "        else:\n",
        "            forecast, residuals, metrics, ci = model_func(train[target], test[target], forecast_index)\n",
        "        \n",
        "        if forecast is None or pd.isna(metrics[0]):\n",
        "            logger.error(f\"{model_name} for {target} failed\")\n",
        "            return None\n",
        "        \n",
        "        if len(forecast) != CONFIG['forecast_horizon']:\n",
        "            logger.error(f\"{model_name} forecast length {len(forecast)} != {CONFIG['forecast_horizon']}\")\n",
        "            return None\n",
        "        \n",
        "        plot_forecast(\n",
        "            train[target][-36:], test[target], forecast, forecast_index,\n",
        "            f'{model_name} Forecast for {target}', target, f'{target}_{model_name}_forecast.png', ci\n",
        "        )\n",
        "        if residuals is not None and len(residuals) > 1:\n",
        "            plot_residual_acf(\n",
        "                residuals.dropna(), f'ACF of Residuals - {model_name} ({target})',\n",
        "                f'{target}_{model_name}_acf.png'\n",
        "            )\n",
        "        \n",
        "        logger.info(f\"Completed {model_name} for {target} in {time.time() - start_time:.2f}s\")\n",
        "        return {\n",
        "            'Target': target,\n",
        "            'Model': model_name,\n",
        "            'RMSE': metrics[0],\n",
        "            'MAE': metrics[1],\n",
        "            'MAPE': metrics[2],\n",
        "            'sMAPE': metrics[3],\n",
        "            'NormMAPE': metrics[4],\n",
        "            'DirAcc': metrics[5],\n",
        "            'Forecast': forecast,\n",
        "            'Residuals': residuals,\n",
        "            'CI': ci\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error running {model_name} for {target}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    logger = setup_logging(CONFIG['img_dir'])\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        # Load và tiền xử lý dữ liệu\n",
        "        cpi_data = pd.read_csv('data/cpi.csv', usecols=['t', 'cpi'])\n",
        "        cpi_data.rename(columns={'t': 'date'}, inplace=True)\n",
        "        cpi_data['time'] = pd.to_datetime(cpi_data['date'], format='%b-%y')\n",
        "        cpi_data.set_index('time', inplace=True)\n",
        "        cpi_data['cpi_mom'] = cpi_data['cpi'].pct_change() * 100\n",
        "        cpi_data = cpi_data[['cpi_mom']].dropna()\n",
        "        logger.info(f\"CPI data shape: {cpi_data.shape}\")\n",
        "        if cpi_data.isna().any().any() or np.isinf(cpi_data).any().any():\n",
        "            logger.warning(\"NaN/Inf in cpi_data, filling...\")\n",
        "            cpi_data = cpi_data.fillna(method='ffill').fillna(cpi_data.mean(numeric_only=True))\n",
        "\n",
        "        exog_data = pd.read_csv('data/exog_data.csv')\n",
        "        exog_data['Ngày'] = pd.to_datetime(exog_data['Ngày'])\n",
        "        exog_data.set_index('Ngày', inplace=True)\n",
        "        exog_cols = ['oil_price', 'gold_price', 'interest_rate']\n",
        "        logger.info(f\"Exogenous data shape: {exog_data.shape}\")\n",
        "        if exog_data.isna().any().any() or np.isinf(exog_data).any().any():\n",
        "            logger.warning(\"NaN/Inf in exog_data, filling...\")\n",
        "            exog_data = exog_data.fillna(method='ffill').fillna(exog_data.mean(numeric_only=True))\n",
        "\n",
        "        # Join và xử lý NaN\n",
        "        data = cpi_data.join(exog_data, how='inner')\n",
        "        logger.info(f\"Joined data shape: {data.shape}\")\n",
        "        if data.isna().any().any() or np.isinf(data).any().any():\n",
        "            logger.warning(\"NaN/Inf in joined data, filling...\")\n",
        "            data = data.fillna(method='ffill').fillna(data.mean(numeric_only=True))\n",
        "\n",
        "        # Kiểm tra đủ dữ liệu cho dự báo\n",
        "        if len(data) < CONFIG['min_data_length'] + CONFIG['forecast_horizon']:\n",
        "            raise ValueError(f\"Data too short: {len(data)} < {CONFIG['min_data_length'] + CONFIG['forecast_horizon']}\")\n",
        "\n",
        "        # Tạo features\n",
        "        data_features = create_features(data, 'cpi_mom', exog_cols)\n",
        "        logger.info(f\"Features shape: {data_features.shape}\")\n",
        "        if data_features.isna().any().any() or np.isinf(data_features).any().any():\n",
        "            logger.warning(\"NaN/Inf in data_features, filling...\")\n",
        "            data_features = data_features.fillna(data_features.mean(numeric_only=True))\n",
        "        \n",
        "        # Split data\n",
        "        train_size = len(data) - CONFIG['forecast_horizon']\n",
        "        train, test = data_features[:train_size], data_features[train_size:]\n",
        "        if len(test) != CONFIG['forecast_horizon']:\n",
        "            raise ValueError(f\"Test set size {len(test)} != forecast_horizon {CONFIG['forecast_horizon']}\")\n",
        "        logger.info(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "        \n",
        "        forecast_index = pd.date_range(start=test.index[0], periods=CONFIG['forecast_horizon'], freq='MS')\n",
        "        logger.info(f\"Forecast index: {forecast_index[0]} to {forecast_index[-1]}\")\n",
        "        \n",
        "        # Plot decomposition\n",
        "        plot_decomposition(data['cpi_mom'], period=CONFIG['seasonal_periods'], \n",
        "                         filename='cpi_mom_decomposition.png')\n",
        "        \n",
        "        # Define models\n",
        "        models = {\n",
        "            'Exponential Smoothing': (run_exponential_smoothing, {}),\n",
        "            'SARIMA': (run_sarima, {}),\n",
        "            'Prophet': (run_prophet, {}),\n",
        "            'XGBoost': (run_xgboost, {}),\n",
        "            'LightGBM': (run_lightgbm, {}),\n",
        "            'SVR': (run_svr, {}),\n",
        "            'LSTM': (run_lstm, {}),\n",
        "            'GRU': (run_gru, {})\n",
        "        }\n",
        "        \n",
        "        # Run base models in parallel\n",
        "        results = []\n",
        "        forecasts_mom = {}\n",
        "        metrics_mom = {}\n",
        "        forecasts_train = {}\n",
        "        forecasts_test = {}\n",
        "        logger.info(\"Running base models for cpi_mom\")\n",
        "        \n",
        "        tasks = [\n",
        "            delayed(run_model_for_target)(\n",
        "                'cpi_mom', train, test, forecast_index, model_name, model_func, params, exog_cols\n",
        "            ) for model_name, (model_func, params) in models.items()\n",
        "        ]\n",
        "        model_results = Parallel(n_jobs=CONFIG['n_jobs'], verbose=1, backend='loky')(tasks)\n",
        "        \n",
        "        # Process base model results\n",
        "        for result in model_results:\n",
        "            if result is not None:\n",
        "                results.append({\n",
        "                    'Target': result['Target'],\n",
        "                    'Model': result['Model'],\n",
        "                    'RMSE': result['RMSE'],\n",
        "                    'MAE': result['MAE'],\n",
        "                    'MAPE': result['MAPE'],\n",
        "                    'sMAPE': result['sMAPE'],\n",
        "                    'NormMAPE': result['NormMAPE'],\n",
        "                    'DirAcc': result['DirAcc']\n",
        "                })\n",
        "                forecasts_mom[result['Model']] = result['Forecast']\n",
        "                metrics_mom[result['Model']] = {'RMSE': result['RMSE']}\n",
        "                forecasts_train[result['Model']] = train['cpi_mom'] - result['Residuals'] if result['Residuals'] is not None else None\n",
        "                forecasts_test[result['Model']] = result['Forecast']\n",
        "        \n",
        "        # Run ensemble models\n",
        "        ensemble_models = {\n",
        "            'Voting Ensemble': (run_voting_ensemble, {'forecasts': forecasts_mom}),\n",
        "            'Weighted Ensemble': (run_weighted_ensemble, {'forecasts': forecasts_mom, 'metrics': metrics_mom}),\n",
        "            'Stacking Ensemble': (run_stacking_ensemble, {'forecasts_train': forecasts_train, 'forecasts_test': forecasts_test})\n",
        "        }\n",
        "        \n",
        "        tasks = [\n",
        "            delayed(run_model_for_target)(\n",
        "                'cpi_mom', train, test, forecast_index, model_name, model_func, params, exog_cols\n",
        "            ) for model_name, (model_func, params) in ensemble_models.items()\n",
        "        ]\n",
        "        ensemble_results = Parallel(n_jobs=CONFIG['n_jobs'], verbose=1, backend='loky')(tasks)\n",
        "        \n",
        "        # Process ensemble results\n",
        "        for result in ensemble_results:\n",
        "            if result is not None:\n",
        "                results.append({\n",
        "                    'Target': result['Target'],\n",
        "                    'Model': result['Model'],\n",
        "                    'RMSE': result['RMSE'],\n",
        "                    'MAE': result['MAE'],\n",
        "                    'MAPE': result['MAPE'],\n",
        "                    'sMAPE': result['sMAPE'],\n",
        "                    'NormMAPE': result['NormMAPE'],\n",
        "                    'DirAcc': result['DirAcc']\n",
        "                })\n",
        "                forecasts_mom[result['Model']] = result['Forecast']\n",
        "                metrics_mom[result['Model']] = {'RMSE': result['RMSE']}\n",
        "        \n",
        "        # Generate comparison plots and save results\n",
        "        if forecasts_mom:\n",
        "            plot_comparison_forecasts(\n",
        "                train['cpi_mom'][-36:], test['cpi_mom'], forecasts_mom, forecast_index,\n",
        "                'Comparison of Forecasts for cpi_mom', 'cpi_mom', \n",
        "                'cpi_mom_model_comparison.png', metrics=metrics_mom\n",
        "            )\n",
        "        \n",
        "        results_df = pd.DataFrame(results)\n",
        "        if not results_df.empty:\n",
        "            print(results_df)\n",
        "            results_df.to_csv(CONFIG['results_file'], index=False)\n",
        "            logger.info(f\"Results saved to {CONFIG['results_file']}\")\n",
        "            plot_metrics_bar(results_df, 'cpi_mom_metrics_comparison.png')\n",
        "        \n",
        "        if forecasts_mom:\n",
        "            combined_forecast = pd.DataFrame({'Date': forecast_index})\n",
        "            for model_name, forecast in forecasts_mom.items():\n",
        "                combined_forecast[f'{model_name}_cpi_mom'] = forecast\n",
        "            combined_forecast.to_csv(f'{CONFIG[\"img_dir\"]}/combined_forecast_cpi_mom.csv', index=False)\n",
        "            logger.info(f\"Combined forecasts saved to {CONFIG['img_dir']}/combined_forecast_cpi_mom.csv\")\n",
        "        \n",
        "        logger.info(f\"Total execution time: {time.time() - start_time:.2f}s\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Main program error: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1f379a5e-6705-48c9-ba5b-f93e5ea97a7b",
        "b305be36-e6cb-44ce-8b82-9cbdd8838dba"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
