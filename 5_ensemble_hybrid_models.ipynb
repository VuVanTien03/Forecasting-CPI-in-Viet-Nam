{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7496e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 14 out of 14 | elapsed:   33.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Target                         Model      RMSE       MAE      MAPE  \\\n",
      "0   cpi_mom                         ARIMA  0.342722  0.274343  0.273675   \n",
      "1   cpi_mom         Exponential Smoothing  0.306036  0.261548  0.261149   \n",
      "2   cpi_mom                       Prophet  0.241324  0.173112  0.172649   \n",
      "3   cpi_mom                        SARIMA  0.314708  0.239793  0.239107   \n",
      "4   cpi_mom                       SARIMAX  0.314708  0.239793  0.239107   \n",
      "5   cpi_mom             Linear Regression  0.318365  0.244097  0.243444   \n",
      "6   cpi_mom                       XGBoost  0.302830  0.212501  0.211616   \n",
      "7   cpi_mom          ARIMA-XGBoost Hybrid  0.310293  0.223061  0.222278   \n",
      "8   cpi_mom            SARIMA-LSTM Hybrid  0.330112  0.251534  0.250820   \n",
      "9   cpi_mom  ETS-Gradient Boosting Hybrid  0.259320  0.225075  0.224679   \n",
      "10  cpi_mom             SARIMA-GRU Hybrid  0.317174  0.236952  0.236244   \n",
      "11  cpi_mom             Weighted Ensemble  0.255814  0.207788  0.207294   \n",
      "12  cpi_mom             Stacking Ensemble  0.333565  0.268316  0.267647   \n",
      "13  cpi_mom               Voting Ensemble  0.296107  0.227573  0.226900   \n",
      "14  cpi_mom                  BMA Ensemble  0.269625  0.217993  0.217403   \n",
      "15  cpi_mom                  DES Ensemble  0.316601  0.243262  0.242573   \n",
      "16  cpi_mom    Temporal Weighted Ensemble  0.271939  0.219346  0.218751   \n",
      "17  cpi_mom           Rank-Based Ensemble  0.231341  0.196218  0.195690   \n",
      "\n",
      "       sMAPE  NormMAPE     DirAcc  \n",
      "0   0.273471  0.002730  63.636364  \n",
      "1   0.260707  0.002605  54.545455  \n",
      "2   0.172564  0.001722  72.727273  \n",
      "3   0.238985  0.002385  54.545455  \n",
      "4   0.238985  0.002385  54.545455  \n",
      "5   0.243339  0.002429  36.363636  \n",
      "6   0.211846  0.002111   0.000000  \n",
      "7   0.222383  0.002217  63.636364  \n",
      "8   0.250682  0.002502  36.363636  \n",
      "9   0.224413  0.002241  54.545455  \n",
      "10  0.236153  0.002357  54.545455  \n",
      "11  0.207118  0.002068  45.454545  \n",
      "12  0.267469  0.002670  54.545455  \n",
      "13  0.226836  0.002263  54.545455  \n",
      "14  0.217298  0.002169  45.454545  \n",
      "15  0.242477  0.002420  45.454545  \n",
      "16  0.218646  0.002182  54.545455  \n",
      "17  0.195582  0.001952  54.545455  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pmdarima as pm\n",
    "from prophet import Prophet\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import matplotlib.dates as mdates\n",
    "import psutil\n",
    "from itertools import product\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "img_dir = 'ensemble_model_results'\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=f'{img_dir}/classical_models_log.txt',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "CONFIG = {\n",
    "    'forecast_horizon': 12,\n",
    "    'seasonal_periods': 12,\n",
    "    'min_data_length': 24,\n",
    "    'img_dir': img_dir,\n",
    "    'results_file': f'{img_dir}/classical_model_results.csv',\n",
    "    'n_jobs': 4,  # Reduced to avoid parallel execution issues\n",
    "    'outlier_threshold': 3,\n",
    "    'max_diff': 3,\n",
    "    'lag_features': list(range(1, 7)),\n",
    "    'rolling_windows': [3, 12],\n",
    "    'correlation_threshold': 0.2,\n",
    "    'batch_size': 1000,\n",
    "    'ensemble_weight_grid': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'des_window': 24,\n",
    "    'temporal_decay': 0.95,\n",
    "    'nn_hidden_layers': (50, 25),\n",
    "    'lstm_units': 50,\n",
    "    'gru_units': 50,\n",
    "    'lstm_sequence_length': 6,  # Reduced to ensure sufficient sequences\n",
    "}\n",
    "\n",
    "def detect_outliers(series, threshold=CONFIG['outlier_threshold']):\n",
    "    z_scores = np.abs((series - series.mean()) / series.std())\n",
    "    outliers = z_scores > threshold\n",
    "    series_clean = series.where(~outliers, series.mean())\n",
    "    logger.info(f\"Detected {outliers.sum()} outliers in series\")\n",
    "    return series_clean\n",
    "\n",
    "def validate_input_data(df, required_columns):\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"Missing required columns: {required_columns}\")\n",
    "    if df.index.duplicated().any():\n",
    "        df = df[~df.index.duplicated(keep='first')]\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df = df.sort_index()\n",
    "    if df[required_columns].isnull().sum().any():\n",
    "        logger.warning(f\"Missing values in data: {df[required_columns].isnull().sum().to_dict()}\")\n",
    "        df[required_columns] = df[required_columns].interpolate(method='time').fillna(df[required_columns].mean())\n",
    "    if np.isinf(df[required_columns]).any().any():\n",
    "        raise ValueError(\"Data contains infinite values!\")\n",
    "    if not all(df[required_columns].dtypes.apply(lambda x: np.issubdtype(x, np.number))):\n",
    "        raise ValueError(\"Some columns are not numeric!\")\n",
    "    return df\n",
    "\n",
    "def check_stationarity(series, name):\n",
    "    max_diff = CONFIG['max_diff']\n",
    "    series_clean = series.dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(series_clean) < 2:\n",
    "        logger.error(f\"{name}: Data too short after cleaning!\")\n",
    "        return 0\n",
    "    d = 0\n",
    "    while d <= max_diff:\n",
    "        result = adfuller(series_clean, maxlag=12, regression='c')\n",
    "        logger.info(f\"ADF Test for {name} (d={d}): Statistic={result[0]:.4f}, p-value={result[1]:.4f}\")\n",
    "        if result[1] < 0.05:\n",
    "            logger.info(f\"{name} stationary at differencing order d={d}\")\n",
    "            return d\n",
    "        if d == max_diff:\n",
    "            logger.warning(f\"{name} not stationary after {max_diff} differencing. Using d={d}.\")\n",
    "            return d\n",
    "        series_clean = series_clean.diff().dropna()\n",
    "        if len(series_clean) < 2:\n",
    "            logger.warning(f\"{name}: Data too short after differencing {d+1}!\")\n",
    "            return d\n",
    "        d += 1\n",
    "    return d\n",
    "\n",
    "def create_features(\n",
    "    data: pd.DataFrame,\n",
    "    target: str,\n",
    "    lags: list = CONFIG['lag_features'],\n",
    "    rolling_windows: list = CONFIG['rolling_windows'],\n",
    "    seasonal_features: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    logger.info(f\"Creating features for {target}, data shape: {data.shape}\")\n",
    "    if len(data) < CONFIG['min_data_length']:\n",
    "        raise ValueError(f\"Data too short: {len(data)} rows\")\n",
    "    if not isinstance(data.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"DataFrame index must be DatetimeIndex\")\n",
    "    exog_var = 'cpi_yoy'\n",
    "    required_cols = [target, exog_var]\n",
    "    if not all(col in data.columns for col in required_cols):\n",
    "        raise ValueError(f\"Missing columns: {required_cols}\")\n",
    "    df = data[required_cols].copy()\n",
    "    df = df.astype(np.float32)\n",
    "    for col in required_cols:\n",
    "        for lag in lags:\n",
    "            df[f'{col}_lag_{lag}'] = df[col].shift(lag, fill_value=df[col].mean())\n",
    "        for window in rolling_windows:\n",
    "            df[f'{col}_roll_mean_{window}'] = df[col].rolling(window=window, min_periods=1).mean()\n",
    "    if seasonal_features:\n",
    "        period = CONFIG['seasonal_periods']\n",
    "        df['month_sin'] = np.sin(2 * np.pi * df.index.month / period).astype(np.float32)\n",
    "        df['month_cos'] = np.cos(2 * np.pi * df.index.month / period).astype(np.float32)\n",
    "        logger.info(\"Added seasonal features\")\n",
    "    df['quarter'] = df.index.quarter.astype(np.int8)\n",
    "    correlations = df.corr()[target].drop(required_cols, errors='ignore')\n",
    "    low_corr_cols = correlations[abs(correlations) < CONFIG['correlation_threshold']].index\n",
    "    if low_corr_cols.any():\n",
    "        logger.info(f\"Dropping low-correlation features: {list(low_corr_cols)}\")\n",
    "        df = df.drop(columns=low_corr_cols)\n",
    "    logger.info(f\"Features after processing: {list(df.columns)}\")\n",
    "    return df\n",
    "\n",
    "def create_lstm_sequences(data, sequence_length):\n",
    "    if len(data) < sequence_length + 1:\n",
    "        logger.error(f\"Insufficient data for sequences: {len(data)} < {sequence_length + 1}\")\n",
    "        return np.array([]), np.array([])\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(data[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    actual = np.array(actual, dtype=np.float32)\n",
    "    predicted = np.array(predicted, dtype=np.float32)\n",
    "    valid_mask = ~np.isnan(actual) & ~np.isnan(predicted) & ~np.isinf(actual) & ~np.isinf(predicted)\n",
    "    actual = actual[valid_mask]\n",
    "    predicted = predicted[valid_mask]\n",
    "    if len(actual) == 0:\n",
    "        logger.warning(\"No valid data for metrics calculation!\")\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mape = mean_absolute_percentage_error(actual, predicted) * 100 if np.all(np.abs(actual) > 1e-8) else np.nan\n",
    "    smape = 100 * np.mean(2 * np.abs(predicted - actual) / (np.abs(actual) + np.abs(predicted)))\n",
    "    norm_mape = mape / np.mean(np.abs(actual)) if not np.isnan(mape) else np.nan\n",
    "    directional_acc = np.mean((np.diff(actual) * np.diff(predicted)) > 0) * 100 if len(actual) > 1 else np.nan\n",
    "    return rmse, mae, mape, smape, norm_mape, directional_acc\n",
    "\n",
    "def plot_decomposition(series, period, filename):\n",
    "    decomposition = seasonal_decompose(series, period=period, model='additive')\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(12, 8), sharex=True)\n",
    "    axes[0].plot(series.index, series, label='Original'); axes[0].legend(loc='upper left')\n",
    "    axes[1].plot(series.index, decomposition.trend, label='Trend'); axes[1].legend(loc='upper left')\n",
    "    axes[2].plot(series.index, decomposition.seasonal, label='Seasonal'); axes[2].legend(loc='upper left')\n",
    "    axes[3].plot(series.index, decomposition.resid, label='Residual'); axes[3].legend(loc='upper left')\n",
    "    axes[3].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    axes[3].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=150, bbox_inches='tight')\n",
    "        logger.info(f\"Saved decomposition plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving decomposition plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_forecast(historical, test, forecast, forecast_index, title, ylabel, filename, confidence_intervals=None):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(historical.index, historical, label='Historical', color='blue')\n",
    "    plt.plot(test.index, test, label='Actual (Test)', color='green')\n",
    "    plt.plot(forecast_index, forecast, label='Forecast', color='orange', linestyle='--', linewidth=2)\n",
    "    if confidence_intervals:\n",
    "        plt.fill_between(forecast_index, confidence_intervals[0], confidence_intervals[1], color='orange', alpha=0.2)\n",
    "    plt.title(title); plt.xlabel('Time'); plt.ylabel(ylabel); plt.legend(); plt.grid(True)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=150, bbox_inches='tight')\n",
    "        logger.info(f\"Saved plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_comparison_forecasts(historical, test, forecasts, forecast_index, title, ylabel, filename, metrics=None):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(historical.index, historical, label='Historical', color='blue')\n",
    "    plt.plot(test.index, test, label='Actual (Test)', color='green')\n",
    "    colors = sns.color_palette(\"husl\", len(forecasts))\n",
    "    for (model_name, forecast), color in zip(forecasts.items(), colors):\n",
    "        rmse = metrics.get(model_name, {}).get('RMSE', np.nan) if metrics else np.nan\n",
    "        if forecast is None or pd.isna(rmse):\n",
    "            continue\n",
    "        plt.plot(forecast_index, forecast, label=f'Forecast {model_name} (RMSE: {rmse:.4f})', linestyle='--', color=color)\n",
    "    plt.title(title); plt.xlabel('Time'); plt.ylabel(ylabel); plt.legend(); plt.grid(True)\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=150, bbox_inches='tight')\n",
    "        logger.info(f\"Saved comparison plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving comparison plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_metrics_bar(metrics_df, filename):\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    metrics = ['RMSE', 'MAE', 'MAPE', 'sMAPE', 'NormMAPE', 'DirAcc']\n",
    "    for i, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.barplot(x='Model', y=metric, data=metrics_df)\n",
    "        plt.title(f'{metric} Comparison')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=150, bbox_inches='tight')\n",
    "        logger.info(f\"Saved metrics bar plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving metrics bar plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_residual_acf(residuals, title, filename):\n",
    "    if residuals is None or len(residuals) < 2:\n",
    "        logger.warning(f\"Skipping ACF: Insufficient residual data - {title}\")\n",
    "        return\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    max_lags = min(12, len(residuals) - 1)\n",
    "    if max_lags < 1:\n",
    "        return\n",
    "    try:\n",
    "        plot_acf(residuals, lags=max_lags, title=title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(CONFIG['img_dir'], filename), dpi=150, bbox_inches='tight')\n",
    "        logger.info(f\"Saved ACF plot: {filename}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving ACF plot: {str(e)}\")\n",
    "    plt.close()\n",
    "\n",
    "def run_exponential_smoothing(train, test, forecast_index, seasonal_periods=CONFIG['seasonal_periods']):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=seasonal_periods).fit(\n",
    "            smoothing_level=0.2, smoothing_slope=0.1, smoothing_seasonal=0.3, optimized=False)\n",
    "        forecast = model.forecast(CONFIG['forecast_horizon'])\n",
    "        residuals = train - model.fittedvalues\n",
    "        forecast = pd.Series(forecast.values, index=forecast_index, dtype=np.float32)\n",
    "        resid_std = np.std(residuals)\n",
    "        ci_lower = forecast - 1.96 * resid_std\n",
    "        ci_upper = forecast + 1.96 * resid_std\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Exponential Smoothing: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, (ci_lower, ci_upper)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Exponential Smoothing: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_arima(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        d = check_stationarity(train, \"ARIMA\")\n",
    "        model = pm.auto_arima(train, start_p=0, start_q=0, max_p=2, max_q=2, d=d, max_d=1,\n",
    "                              seasonal=False, stepwise=True, trace=False, error_action='ignore',\n",
    "                              suppress_warnings=True, information_criterion='aic', maxiter=30)\n",
    "        forecast = model.predict(n_periods=CONFIG['forecast_horizon'])\n",
    "        residuals = train - model.predict_in_sample()\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"ARIMA (order={model.order}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error ARIMA: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_sarima(train, test, forecast_index, seasonal_periods=CONFIG['seasonal_periods']):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        d = check_stationarity(train, \"SARIMA\")\n",
    "        model = pm.auto_arima(train, start_p=0, start_q=0, max_p=2, max_q=2, d=d, max_d=1,\n",
    "                              seasonal=True, m=seasonal_periods, start_P=0, start_Q=0, max_P=1, max_Q=1, max_D=1,\n",
    "                              stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
    "                              information_criterion='aic', maxiter=30)\n",
    "        forecast = model.predict(n_periods=CONFIG['forecast_horizon'])\n",
    "        residuals = train - model.predict_in_sample()\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"SARIMA (order={model.order}, seasonal_order={model.seasonal_order}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error SARIMA: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_sarimax(train, test, forecast_index, exog_train, exog_test):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        exog_train = exog_train.fillna(exog_train.mean())\n",
    "        exog_test = exog_test.fillna(exog_test.mean())\n",
    "        if len(exog_train) != len(train) or len(exog_test) != CONFIG['forecast_horizon']:\n",
    "            raise ValueError(f\"Exogenous data size mismatch\")\n",
    "        d = check_stationarity(train, \"SARIMAX\")\n",
    "        model = pm.auto_arima(train, exogenous=exog_train, start_p=0, start_q=0, max_p=2, max_q=2, d=d, max_d=1,\n",
    "                              seasonal=True, m=CONFIG['seasonal_periods'], start_P=0, start_Q=0, max_P=1, max_Q=1, max_D=1,\n",
    "                              stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
    "                              information_criterion='aic', maxiter=30)\n",
    "        forecast = model.predict(n_periods=CONFIG['forecast_horizon'], exogenous=exog_test)\n",
    "        residuals = train - model.predict_in_sample(exogenous=exog_train)\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"SARIMAX (order={model.order}, seasonal_order={model.seasonal_order}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error SARIMAX: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_prophet(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        df_train = pd.DataFrame({'ds': train.index, 'y': train.values})\n",
    "        model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False,\n",
    "                        changepoint_prior_scale=0.05, seasonality_prior_scale=10.0, n_changepoints=10).fit(df_train)\n",
    "        future = pd.DataFrame({'ds': forecast_index})\n",
    "        forecast = model.predict(future)\n",
    "        forecast_series = pd.Series(forecast['yhat'].values, index=forecast_index, dtype=np.float32)\n",
    "        residuals = train - model.predict(df_train)['yhat']\n",
    "        ci_lower = pd.Series(forecast['yhat_lower'].values, index=forecast_index, dtype=np.float32)\n",
    "        ci_upper = pd.Series(forecast['yhat_upper'].values, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast_series)\n",
    "        logger.info(f\"Prophet: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast_series, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, (ci_lower, ci_upper)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Prophet: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_linear_regression(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        X_train = np.arange(len(train)).reshape(-1, 1).astype(np.float32)\n",
    "        X_test = np.arange(len(train), len(train) + CONFIG['forecast_horizon']).reshape(-1, 1).astype(np.float32)\n",
    "        model = LinearRegression(n_jobs=1).fit(X_train, train)\n",
    "        forecast = model.predict(X_test)\n",
    "        residuals = train - model.predict(X_train)\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Linear Regression: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Linear Regression: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_xgboost(train, test, forecast_index, exog_train, exog_test):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        exog_train = exog_train.fillna(exog_train.mean())\n",
    "        exog_test = exog_test.fillna(exog_test.mean())\n",
    "        scaler = StandardScaler()\n",
    "        exog_train_scaled = scaler.fit_transform(exog_train).astype(np.float32)\n",
    "        exog_test_scaled = scaler.transform(exog_test).astype(np.float32)\n",
    "        param_grid = {\n",
    "            'n_estimators': [50],\n",
    "            'learning_rate': [0.05],\n",
    "            'max_depth': [3],\n",
    "            'subsample': [0.8]\n",
    "        }\n",
    "        model = GridSearchCV(\n",
    "            XGBRegressor(random_state=42, tree_method='hist'),\n",
    "            param_grid,\n",
    "            cv=TimeSeriesSplit(n_splits=3),\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=1\n",
    "        )\n",
    "        model.fit(exog_train_scaled, train)\n",
    "        logger.info(f\"Best XGBoost params: {model.best_params_}\")\n",
    "        forecast = model.predict(exog_test_scaled)\n",
    "        residuals = train - model.predict(exog_train_scaled)\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"XGBoost: RMSE={rmse:.4f}, DirAcc={dir_acc:.2f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error XGBoost: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_arima_xgboost_hybrid(train, test, forecast_index, exog_train, exog_test):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        d = check_stationarity(train, \"ARIMA-XGBoost\")\n",
    "        arima_model = pm.auto_arima(train, start_p=0, start_q=0, max_p=2, max_q=2, d=d, max_d=1,\n",
    "                                    seasonal=False, stepwise=True, trace=False, error_action='ignore',\n",
    "                                    suppress_warnings=True, information_criterion='aic', maxiter=30)\n",
    "        arima_fitted = arima_model.predict_in_sample()\n",
    "        arima_forecast = arima_model.predict(n_periods=CONFIG['forecast_horizon'])\n",
    "        residuals = train - arima_fitted\n",
    "        exog_train = exog_train.fillna(exog_train.mean())\n",
    "        exog_test = exog_test.fillna(exog_test.mean())\n",
    "        scaler = StandardScaler()\n",
    "        exog_train_scaled = scaler.fit_transform(exog_train).astype(np.float32)\n",
    "        exog_test_scaled = scaler.transform(exog_test).astype(np.float32)\n",
    "        xgb_model = XGBRegressor(n_estimators=50, learning_rate=0.05, max_depth=3, subsample=0.8,\n",
    "                                 random_state=42, tree_method='hist')\n",
    "        xgb_model.fit(exog_train_scaled, residuals)\n",
    "        residual_forecast = xgb_model.predict(exog_test_scaled)\n",
    "        forecast = arima_forecast + residual_forecast\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"ARIMA-XGBoost Hybrid: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, None, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error ARIMA-XGBoost Hybrid: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_prophet_nn_hybrid(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        df_train = pd.DataFrame({'ds': train.index, 'y': train.values})\n",
    "        prophet_model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False,\n",
    "                                changepoint_prior_scale=0.05, seasonality_prior_scale=10.0, n_changepoints=10).fit(df_train)\n",
    "        future = pd.DataFrame({'ds': forecast_index})\n",
    "        prophet_forecast = prophet_model.predict(future)\n",
    "        prophet_fitted = prophet_model.predict(df_train)\n",
    "        residuals = train - prophet_fitted['yhat']\n",
    "        X_train = np.arange(len(train)).reshape(-1, 1).astype(np.float32)\n",
    "        X_test = np.arange(len(train), len(train) + CONFIG['forecast_horizon']).reshape(-1, 1).astype(np.float32)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        nn_model = MLPRegressor(hidden_layer_sizes=CONFIG['nn_hidden_layers'], activation='relu',\n",
    "                                solver='adam', max_iter=200, random_state=42)\n",
    "        nn_model.fit(X_train_scaled, residuals)\n",
    "        residual_forecast = nn_model.predict(X_test_scaled)\n",
    "        forecast = prophet_forecast['yhat'].values + residual_forecast\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Prophet-NN Hybrid: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, None, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Prophet-NN Hybrid: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_sarima_stacking_hybrid(train, test, forecast_index, exog_train, exog_test):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        d = check_stationarity(train, \"SARIMA-Stacking\")\n",
    "        sarima_model = pm.auto_arima(train, start_p=0, start_q=0, max_p=2, max_q=2, d=d, max_d=1,\n",
    "                                     seasonal=True, m=CONFIG['seasonal_periods'], start_P=0, start_Q=0, max_P=1, max_Q=1, max_D=1,\n",
    "                                     stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
    "                                     information_criterion='aic', maxiter=30)\n",
    "        sarima_fitted = sarima_model.predict_in_sample()\n",
    "        sarima_forecast = sarima_model.predict(n_periods=CONFIG['forecast_horizon'])\n",
    "        exog_train = exog_train.fillna(exog_train.mean())\n",
    "        exog_test = exog_test.fillna(exog_test.mean())\n",
    "        train_features = exog_train.copy()\n",
    "        test_features = exog_test.copy()\n",
    "        train_features['sarima_fitted'] = sarima_fitted\n",
    "        test_features['sarima_forecast'] = sarima_forecast\n",
    "        scaler = StandardScaler()\n",
    "        train_features_scaled = scaler.fit_transform(train_features).astype(np.float32)\n",
    "        test_features_scaled = scaler.transform(test_features).astype(np.float32)\n",
    "        xgb_model = XGBRegressor(n_estimators=50, learning_rate=0.05, max_depth=3, subsample=0.8,\n",
    "                                 random_state=42, tree_method='hist')\n",
    "        xgb_model.fit(train_features_scaled, train)\n",
    "        forecast = xgb_model.predict(test_features_scaled)\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"SARIMA-Stacking Hybrid: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, None, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error SARIMA-Stacking Hybrid: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_sarima_lstm_hybrid(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Step 1: Fit SARIMA model\n",
    "        d = check_stationarity(train, \"SARIMA-LSTM\")\n",
    "        sarima_model = pm.auto_arima(train, start_p=0, start_q=0, max_p=2, max_q=2, d=d, max_d=1,\n",
    "                                     seasonal=True, m=CONFIG['seasonal_periods'], start_P=0, start_Q=0, max_P=1, max_Q=1, max_D=1,\n",
    "                                     stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
    "                                     information_criterion='aic', maxiter=30)\n",
    "        sarima_fitted = sarima_model.predict_in_sample()\n",
    "        sarima_forecast = sarima_model.predict(n_periods=CONFIG['forecast_horizon'])\n",
    "        residuals = train - sarima_fitted\n",
    "        # Step 2: Prepare data for LSTM\n",
    "        scaler = StandardScaler()\n",
    "        residuals_scaled = scaler.fit_transform(residuals.values.reshape(-1, 1)).astype(np.float32)\n",
    "        sequence_length = CONFIG['lstm_sequence_length']\n",
    "        X_train, y_train = create_lstm_sequences(residuals_scaled, sequence_length)\n",
    "        if len(X_train) == 0 or len(y_train) == 0:\n",
    "            logger.error(\"Insufficient data for LSTM sequences\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        # Step 3: Build and train LSTM model\n",
    "        lstm_model = Sequential([\n",
    "            LSTM(CONFIG['lstm_units'], input_shape=(sequence_length, 1), return_sequences=False),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        lstm_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "        # Step 4: Forecast residuals\n",
    "        last_sequence = residuals_scaled[-sequence_length:].reshape(1, sequence_length, 1)\n",
    "        residual_forecast_scaled = []\n",
    "        for _ in range(CONFIG['forecast_horizon']):\n",
    "            pred = lstm_model.predict(last_sequence, verbose=0)\n",
    "            residual_forecast_scaled.append(pred[0, 0])\n",
    "            last_sequence = np.roll(last_sequence, -1, axis=1)\n",
    "            last_sequence[0, -1, 0] = pred[0, 0]\n",
    "        residual_forecast = scaler.inverse_transform(np.array(residual_forecast_scaled).reshape(-1, 1)).flatten()\n",
    "        # Step 5: Combine forecasts\n",
    "        forecast = sarima_forecast + residual_forecast\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"SARIMA-LSTM Hybrid: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, None, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error SARIMA-LSTM Hybrid: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_sarima_gru_hybrid(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Step 1: Fit SARIMA model\n",
    "        d = check_stationarity(train, \"SARIMA-GRU\")\n",
    "        sarima_model = pm.auto_arima(train, start_p=0, start_q=0, max_p=2, max_q=2, d=d, max_d=1,\n",
    "                                     seasonal=True, m=CONFIG['seasonal_periods'], start_P=0, start_Q=0, max_P=1, max_Q=1, max_D=1,\n",
    "                                     stepwise=True, trace=False, error_action='ignore', suppress_warnings=True,\n",
    "                                     information_criterion='aic', maxiter=30)\n",
    "        sarima_fitted = sarima_model.predict_in_sample()\n",
    "        sarima_forecast = sarima_model.predict(n_periods=CONFIG['forecast_horizon'])\n",
    "        residuals = train - sarima_fitted\n",
    "        # Step 2: Prepare data for GRU\n",
    "        scaler = StandardScaler()\n",
    "        residuals_scaled = scaler.fit_transform(residuals.values.reshape(-1, 1)).astype(np.float32)\n",
    "        sequence_length = CONFIG['lstm_sequence_length']\n",
    "        X_train, y_train = create_lstm_sequences(residuals_scaled, sequence_length)\n",
    "        if len(X_train) == 0 or len(y_train) == 0:\n",
    "            logger.error(\"Insufficient data for GRU sequences\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        # Step 3: Build and train GRU model\n",
    "        gru_model = Sequential([\n",
    "            GRU(CONFIG['gru_units'], input_shape=(sequence_length, 1), return_sequences=False),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        gru_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "        # Step 4: Forecast residuals\n",
    "        last_sequence = residuals_scaled[-sequence_length:].reshape(1, sequence_length, 1)\n",
    "        residual_forecast_scaled = []\n",
    "        for _ in range(CONFIG['forecast_horizon']):\n",
    "            pred = gru_model.predict(last_sequence, verbose=0)\n",
    "            residual_forecast_scaled.append(pred[0, 0])\n",
    "            last_sequence = np.roll(last_sequence, -1, axis=1)\n",
    "            last_sequence[0, -1, 0] = pred[0, 0]\n",
    "        residual_forecast = scaler.inverse_transform(np.array(residual_forecast_scaled).reshape(-1, 1)).flatten()\n",
    "        # Step 5: Combine forecasts\n",
    "        forecast = sarima_forecast + residual_forecast\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"SARIMA-GRU Hybrid: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, None, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error SARIMA-GRU Hybrid: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_prophet_xgboost_hybrid(train, test, forecast_index, exog_train, exog_test):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        df_train = pd.DataFrame({'ds': train.index, 'y': train.values})\n",
    "        prophet_model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False,\n",
    "                                changepoint_prior_scale=0.05, seasonality_prior_scale=10.0, n_changepoints=10).fit(df_train)\n",
    "        future = pd.DataFrame({'ds': forecast_index})\n",
    "        prophet_forecast = prophet_model.predict(future)\n",
    "        prophet_fitted = prophet_model.predict(df_train)\n",
    "        residuals = train - prophet_fitted['yhat']\n",
    "        exog_train = exog_train.fillna(exog_train.mean())\n",
    "        exog_test = exog_test.fillna(exog_test.mean())\n",
    "        scaler = StandardScaler()\n",
    "        exog_train_scaled = scaler.fit_transform(exog_train).astype(np.float32)\n",
    "        exog_test_scaled = scaler.transform(exog_test).astype(np.float32)\n",
    "        xgb_model = XGBRegressor(n_estimators=50, learning_rate=0.05, max_depth=3, subsample=0.8,\n",
    "                                 random_state=42, tree_method='hist')\n",
    "        xgb_model.fit(exog_train_scaled, residuals)\n",
    "        residual_forecast = xgb_model.predict(exog_test_scaled)\n",
    "        forecast = prophet_forecast['yhat'].values + residual_forecast\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Prophet-XGBoost Hybrid: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, None, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Prophet-XGBoost Hybrid: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_ets_gradient_boosting_hybrid(train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        ets_model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=CONFIG['seasonal_periods']).fit(\n",
    "            smoothing_level=0.2, smoothing_slope=0.1, smoothing_seasonal=0.3, optimized=False)\n",
    "        ets_fitted = ets_model.fittedvalues\n",
    "        ets_forecast = ets_model.forecast(CONFIG['forecast_horizon'])\n",
    "        residuals = train - ets_fitted\n",
    "        X_train = np.arange(len(train)).reshape(-1, 1).astype(np.float32)\n",
    "        X_test = np.arange(len(train), len(train) + CONFIG['forecast_horizon']).reshape(-1, 1).astype(np.float32)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        gb_model = GradientBoostingRegressor(n_estimators=50, learning_rate=0.05, max_depth=3, random_state=42)\n",
    "        gb_model.fit(X_train_scaled, residuals)\n",
    "        residual_forecast = gb_model.predict(X_test_scaled)\n",
    "        forecast = ets_forecast + residual_forecast\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"ETS-Gradient Boosting Hybrid: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, None, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error ETS-Gradient Boosting Hybrid: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_weighted_ensemble(forecasts, metrics, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        models = [m for m in forecasts if metrics[m]['RMSE'] > 0 and not pd.isna(metrics[m]['RMSE'])]\n",
    "        if not models:\n",
    "            logger.error(\"No valid models for weighted ensemble\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        best_rmse = np.inf\n",
    "        best_weights = None\n",
    "        weight_grid = CONFIG['ensemble_weight_grid']\n",
    "        weight_combinations = list(product(weight_grid, repeat=len(models)))\n",
    "        for weights in weight_combinations[:100]:\n",
    "            weights = np.array(weights) / np.sum(weights)\n",
    "            forecast = pd.Series(0, index=forecast_index, dtype=np.float32)\n",
    "            for model, weight in zip(models, weights):\n",
    "                forecast += weight * forecasts[model]\n",
    "            rmse = np.sqrt(mean_squared_error(test, forecast))\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_weights = dict(zip(models, weights))\n",
    "        forecast = pd.Series(0, index=forecast_index, dtype=np.float32)\n",
    "        for model, weight in best_weights.items():\n",
    "            forecast += weight * forecasts[model]\n",
    "        residuals = None\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Weighted Ensemble (weights={best_weights}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Weighted Ensemble: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_stacking_ensemble(forecasts, metrics, train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        models = [m for m in forecasts if metrics[m]['RMSE'] > 0 and not pd.isna(metrics[m]['RMSE'])]\n",
    "        if not models:\n",
    "            logger.error(\"No valid models for stacking ensemble\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        train_forecasts = pd.DataFrame({model: forecasts[model].reindex(train.index, method='nearest') for model in models})\n",
    "        test_forecasts = pd.DataFrame({model: forecasts[model] for model in models})\n",
    "        train_forecasts = train_forecasts.fillna(train_forecasts.mean())\n",
    "        test_forecasts = test_forecasts.fillna(test_forecasts.mean())\n",
    "        meta_model = LinearRegression(n_jobs=1)\n",
    "        meta_model.fit(train_forecasts, train)\n",
    "        forecast = meta_model.predict(test_forecasts)\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        residuals = None\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Stacking Ensemble: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Stacking Ensemble: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_voting_ensemble(forecasts, metrics, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        models = [m for m in forecasts if metrics[m]['RMSE'] > 0 and not pd.isna(metrics[m]['RMSE'])]\n",
    "        if not models:\n",
    "            logger.error(\"No valid models for voting ensemble\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        forecast_df = pd.DataFrame({model: forecasts[model] for model in models})\n",
    "        forecast = forecast_df.median(axis=1)\n",
    "        forecast = pd.Series(forecast, index=forecast_index, dtype=np.float32)\n",
    "        residuals = None\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Voting Ensemble (Median): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Voting Ensemble: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_bma_ensemble(forecasts, metrics, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        models = [m for m in forecasts if metrics[m]['RMSE'] > 0 and not pd.isna(metrics[m]['RMSE'])]\n",
    "        if not models:\n",
    "            logger.error(\"No valid models for BMA ensemble\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        rmse_values = np.array([metrics[m]['RMSE'] for m in models])\n",
    "        bic_approx = np.log(rmse_values ** 2 * len(test))\n",
    "        weights = np.exp(-0.5 * bic_approx)\n",
    "        weights = weights / np.sum(weights)\n",
    "        forecast = pd.Series(0, index=forecast_index, dtype=np.float32)\n",
    "        for model, weight in zip(models, weights):\n",
    "            forecast += weight * forecasts[model]\n",
    "        residuals = None\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"BMA Ensemble (weights={dict(zip(models, weights))}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error BMA Ensemble: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_des_ensemble(forecasts, metrics, train, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        models = [m for m in forecasts if metrics[m]['RMSE'] > 0 and not pd.isna(metrics[m]['RMSE'])]\n",
    "        if not models:\n",
    "            logger.error(\"No valid models for DES ensemble\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        window = CONFIG['des_window']\n",
    "        train_forecasts = pd.DataFrame({model: forecasts[model].reindex(train.index, method='nearest') for model in models})\n",
    "        train_forecasts = train_forecasts.fillna(train_forecasts.mean())\n",
    "        forecast = pd.Series(0, index=forecast_index, dtype=np.float32)\n",
    "        for i in range(len(forecast_index)):\n",
    "            start_idx = max(0, len(train) - window)\n",
    "            window_data = train[start_idx:]\n",
    "            window_forecasts = train_forecasts[start_idx:]\n",
    "            rmses = {}\n",
    "            for model in models:\n",
    "                rmse = np.sqrt(mean_squared_error(window_data, window_forecasts[model]))\n",
    "                rmses[model] = rmse\n",
    "            top_models = sorted(rmses, key=rmses.get)[:3]\n",
    "            if not top_models:\n",
    "                top_models = models\n",
    "            weights = [1 / rmses[m] for m in top_models]\n",
    "            weights = np.array(weights) / np.sum(weights)\n",
    "            forecast[i] = sum(w * forecasts[m][i] for m, w in zip(top_models, weights))\n",
    "        residuals = None\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"DES Ensemble: RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error DES Ensemble: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_temporal_weighted_ensemble(forecasts, metrics, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        models = [m for m in forecasts if metrics[m]['RMSE'] > 0 and not pd.isna(metrics[m]['RMSE'])]\n",
    "        if not models:\n",
    "            logger.error(\"No valid models for temporal weighted ensemble\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        decay = CONFIG['temporal_decay']\n",
    "        rmse_values = np.array([metrics[m]['RMSE'] for m in models])\n",
    "        weights = np.array([decay ** (i / len(test)) / rmse for i, rmse in enumerate(rmse_values)])\n",
    "        weights = weights / np.sum(weights)\n",
    "        forecast = pd.Series(0, index=forecast_index, dtype=np.float32)\n",
    "        for model, weight in zip(models, weights):\n",
    "            forecast += weight * forecasts[model]\n",
    "        residuals = None\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Temporal Weighted Ensemble (weights={dict(zip(models, weights))}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Temporal Weighted Ensemble: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_rank_based_ensemble(forecasts, metrics, test, forecast_index):\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        models = [m for m in forecasts if metrics[m]['RMSE'] > 0 and not pd.isna(metrics[m]['RMSE'])]\n",
    "        if not models:\n",
    "            logger.error(\"No valid models for rank-based ensemble\")\n",
    "            return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "        rmse_values = np.array([metrics[m]['RMSE'] for m in models])\n",
    "        ranks = rankdata(rmse_values, method='average')\n",
    "        weights = 1 / ranks\n",
    "        weights = weights / np.sum(weights)\n",
    "        forecast = pd.Series(0, index=forecast_index, dtype=np.float32)\n",
    "        for model, weight in zip(models, weights):\n",
    "            forecast += weight * forecasts[model]\n",
    "        residuals = None\n",
    "        rmse, mae, mape, smape, norm_mape, dir_acc = calculate_metrics(test, forecast)\n",
    "        logger.info(f\"Rank-Based Ensemble (weights={dict(zip(models, weights))}): RMSE={rmse:.4f}, Time={time.time() - start_time:.2f}s\")\n",
    "        return forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error Rank-Based Ensemble: {str(e)}\")\n",
    "        return None, None, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, None\n",
    "\n",
    "def run_model_for_target(target, train, test, forecast_index, model_name, model_func, params):\n",
    "    logger.info(f\"Running {model_name} for {target}\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        if model_name in ['SARIMAX', 'XGBoost', 'ARIMA-XGBoost Hybrid', 'SARIMA-Stacking Hybrid', \n",
    "                          'Prophet-XGBoost Hybrid']:\n",
    "            exog_var = 'cpi_yoy'\n",
    "            feature_cols = [exog_var] + [f'{target}_lag_{lag}' for lag in CONFIG['lag_features']] + \\\n",
    "                           [f'{target}_roll_mean_{w}' for w in CONFIG['rolling_windows']] + \\\n",
    "                           [f'{exog_var}_lag_{lag}' for lag in CONFIG['lag_features']] + \\\n",
    "                           [f'{exog_var}_roll_mean_{w}' for w in CONFIG['rolling_windows']] + \\\n",
    "                           ['month_sin', 'month_cos', 'quarter']\n",
    "            feature_cols = [col for col in feature_cols if col in train.columns]\n",
    "            exog_train = train[feature_cols]\n",
    "            exog_test = pd.DataFrame(index=forecast_index, dtype=np.float32)\n",
    "            exog_test[exog_var] = test[exog_var].reindex(forecast_index).fillna(train[exog_var].mean())\n",
    "            for col in feature_cols:\n",
    "                if col != exog_var:\n",
    "                    exog_test[col] = train[col].iloc[-1] if col in train.columns else train[exog_var].mean()\n",
    "            forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, ci = model_func(\n",
    "                train[target], test[target], forecast_index, exog_train, exog_test, **params\n",
    "            )\n",
    "        elif model_name in ['Weighted Ensemble', 'Stacking Ensemble', 'Voting Ensemble', 'BMA Ensemble', \n",
    "                           'DES Ensemble', 'Temporal Weighted Ensemble', 'Rank-Based Ensemble']:\n",
    "            if model_name in ['Stacking Ensemble', 'DES Ensemble']:\n",
    "                params['train'] = train[target]\n",
    "                forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, ci = model_func(\n",
    "                    params['forecasts'], params['metrics'], train[target], test[target], forecast_index\n",
    "                )\n",
    "            else:\n",
    "                forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, ci = model_func(\n",
    "                    params['forecasts'], params['metrics'], test[target], forecast_index\n",
    "                )\n",
    "        else:\n",
    "            forecast, residuals, rmse, mae, mape, smape, norm_mape, dir_acc, ci = model_func(\n",
    "                train[target], test[target], forecast_index, **params\n",
    "            )\n",
    "        if forecast is None or pd.isna(rmse):\n",
    "            logger.error(f\"{model_name} for {target} failed to produce valid forecast or RMSE\")\n",
    "            return None\n",
    "        plot_forecast(train[target][-36:], test[target], forecast, forecast_index,\n",
    "                      f'{model_name} Forecast for {target}', target, f'{target}_{model_name}_forecast.png', ci)\n",
    "        if residuals is not None:\n",
    "            plot_residual_acf(residuals.dropna(), f'ACF of Residuals - {model_name} ({target})',\n",
    "                              f'{target}_{model_name}_acf.png')\n",
    "        logger.info(f\"Completed {model_name} for {target} in {time.time() - start_time:.2f}s\")\n",
    "        return {\n",
    "            'Target': target,\n",
    "            'Model': model_name,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE': mape,\n",
    "            'sMAPE': smape,\n",
    "            'NormMAPE': norm_mape,\n",
    "            'DirAcc': dir_acc,\n",
    "            'Forecast': forecast,\n",
    "            'Residuals': residuals,\n",
    "            'CI': ci\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running {model_name} for {target}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        data = pd.read_csv('data/analyzed_time_series.csv', parse_dates=['time'], index_col='time')\n",
    "        data = data.asfreq('MS')\n",
    "        required_columns = ['cpi_mom', 'cpi_yoy']\n",
    "        data = validate_input_data(data, required_columns)\n",
    "        for col in required_columns:\n",
    "            data[col] = detect_outliers(data[col])\n",
    "        data_features = create_features(data, 'cpi_mom')\n",
    "        train_size = len(data) - CONFIG['forecast_horizon']\n",
    "        train, test = data_features[:train_size], data_features[train_size:]\n",
    "        forecast_index = pd.date_range(start=test.index[0], periods=CONFIG['forecast_horizon'], freq='MS')\n",
    "        plot_decomposition(data['cpi_mom'], period=CONFIG['seasonal_periods'], filename='cpi_mom_decomposition.png')\n",
    "        models = {\n",
    "            'ARIMA': (run_arima, {}),\n",
    "            'Exponential Smoothing': (run_exponential_smoothing, {}),\n",
    "            'Prophet': (run_prophet, {}),\n",
    "            'SARIMA': (run_sarima, {}),\n",
    "            'SARIMAX': (run_sarimax, {}),\n",
    "            'Linear Regression': (run_linear_regression, {}),\n",
    "            'XGBoost': (run_xgboost, {}),\n",
    "            'ARIMA-XGBoost Hybrid': (run_arima_xgboost_hybrid, {}),\n",
    "            'Prophet-NN Hybrid': (run_prophet_nn_hybrid, {}),\n",
    "            'SARIMA-Stacking Hybrid': (run_sarima_stacking_hybrid, {}),\n",
    "            'SARIMA-LSTM Hybrid': (run_sarima_lstm_hybrid, {}),\n",
    "            'Prophet-XGBoost Hybrid': (run_prophet_xgboost_hybrid, {}),\n",
    "            'ETS-Gradient Boosting Hybrid': (run_ets_gradient_boosting_hybrid, {}),\n",
    "            'SARIMA-GRU Hybrid': (run_sarima_gru_hybrid, {}),\n",
    "        }\n",
    "        results = []\n",
    "        forecasts_mom = {}\n",
    "        metrics_mom = {}\n",
    "        logger.info(\"Running base and hybrid models for cpi_mom\")\n",
    "        tasks = [delayed(run_model_for_target)('cpi_mom', train, test, forecast_index, model_name, model_func, params)\n",
    "                 for model_name, (model_func, params) in models.items()]\n",
    "        model_results = Parallel(n_jobs=CONFIG['n_jobs'], verbose=1, backend='loky')(tasks)\n",
    "        for result in model_results:\n",
    "            if result is not None:\n",
    "                results.append({\n",
    "                    'Target': result['Target'],\n",
    "                    'Model': result['Model'],\n",
    "                    'RMSE': result['RMSE'],\n",
    "                    'MAE': result['MAE'],\n",
    "                    'MAPE': result['MAPE'],\n",
    "                    'sMAPE': result['sMAPE'],\n",
    "                    'NormMAPE': result['NormMAPE'],\n",
    "                    'DirAcc': result['DirAcc']\n",
    "                })\n",
    "                forecasts_mom[result['Model']] = result['Forecast']\n",
    "                metrics_mom[result['Model']] = {'RMSE': result['RMSE']}\n",
    "            else:\n",
    "                logger.warning(f\"Result for a cpi_mom model is None, skipping!\")\n",
    "        if forecasts_mom:\n",
    "            ensemble_methods = [\n",
    "                ('Weighted Ensemble', run_weighted_ensemble),\n",
    "                ('Stacking Ensemble', run_stacking_ensemble),\n",
    "                ('Voting Ensemble', run_voting_ensemble),\n",
    "                ('BMA Ensemble', run_bma_ensemble),\n",
    "                ('DES Ensemble', run_des_ensemble),\n",
    "                ('Temporal Weighted Ensemble', run_temporal_weighted_ensemble),\n",
    "                ('Rank-Based Ensemble', run_rank_based_ensemble)\n",
    "            ]\n",
    "            for ensemble_name, ensemble_func in ensemble_methods:\n",
    "                ensemble_result = run_model_for_target(\n",
    "                    'cpi_mom', train, test, forecast_index, ensemble_name, ensemble_func,\n",
    "                    {'forecasts': forecasts_mom, 'metrics': metrics_mom}\n",
    "                )\n",
    "                if ensemble_result is not None:\n",
    "                    results.append({\n",
    "                        'Target': ensemble_result['Target'],\n",
    "                        'Model': ensemble_result['Model'],\n",
    "                        'RMSE': ensemble_result['RMSE'],\n",
    "                        'MAE': ensemble_result['MAE'],\n",
    "                        'MAPE': ensemble_result['MAPE'],\n",
    "                        'sMAPE': ensemble_result['sMAPE'],\n",
    "                        'NormMAPE': ensemble_result['NormMAPE'],\n",
    "                        'DirAcc': ensemble_result['DirAcc']\n",
    "                    })\n",
    "                    forecasts_mom[ensemble_result['Model']] = ensemble_result['Forecast']\n",
    "                    metrics_mom[ensemble_result['Model']] = {'RMSE': ensemble_result['RMSE']}\n",
    "        if forecasts_mom:\n",
    "            plot_comparison_forecasts(train['cpi_mom'][-36:], test['cpi_mom'], forecasts_mom, forecast_index,\n",
    "                                     'Comparison of Forecasts for cpi_mom', 'cpi_mom', 'cpi_mom_model_comparison.png',\n",
    "                                     metrics=metrics_mom)\n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(results_df)\n",
    "        results_df.to_csv(CONFIG['results_file'], index=False)\n",
    "        logger.info(f\"Results saved to {CONFIG['results_file']}\")\n",
    "        if not results_df.empty:\n",
    "            plot_metrics_bar(results_df, 'cpi_mom_metrics_comparison.png')\n",
    "        if forecasts_mom:\n",
    "            combined_forecast = pd.DataFrame({'Date': forecast_index})\n",
    "            for model_name, forecast in forecasts_mom.items():\n",
    "                combined_forecast[f'{model_name}_cpi_mom'] = forecast\n",
    "            combined_forecast.to_csv(f'{img_dir}/combined_forecast_cpi_mom.csv', index=False)\n",
    "            logger.info(f\"Combined forecasts saved to {img_dir}/combined_forecast_cpi_mom.csv\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main program error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
